{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8acb9d04-9d73-4e57-9b80-5d9a1bbc8d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dff9688-f139-4743-8ca0-08ccbf67cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "635dcbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHIDPN</th>\n",
       "      <th>S1HHIDPN</th>\n",
       "      <th>R1MSTAT</th>\n",
       "      <th>R1MPART</th>\n",
       "      <th>S1BMONTH</th>\n",
       "      <th>S1BYEAR</th>\n",
       "      <th>S1BDATE</th>\n",
       "      <th>S1BFLAG</th>\n",
       "      <th>S1COHBYR</th>\n",
       "      <th>S1HRSAMP</th>\n",
       "      <th>...</th>\n",
       "      <th>R8LBSATWLF</th>\n",
       "      <th>R9LBSATWLF</th>\n",
       "      <th>R10LBSATWLF</th>\n",
       "      <th>R11LBSATWLF</th>\n",
       "      <th>R12LBSATWLF</th>\n",
       "      <th>R13LBSATWLF</th>\n",
       "      <th>R14LBSATWLF</th>\n",
       "      <th>R15LBSATWLF</th>\n",
       "      <th>R16LBSATWLF</th>\n",
       "      <th>FILEVER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3010</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>-7778.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3020</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>-8752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HHIDPN  S1HHIDPN  R1MSTAT  R1MPART  S1BMONTH  S1BYEAR  S1BDATE  S1BFLAG  \\\n",
       "0      1010       0.0      5.0      0.0       NaN      NaN      NaN      NaN   \n",
       "1      2010       0.0      7.0      0.0       NaN      NaN      NaN      NaN   \n",
       "2      3010    3020.0      1.0      0.0       9.0   1938.0  -7778.0      0.0   \n",
       "3      3020    3010.0      1.0      0.0       1.0   1936.0  -8752.0      0.0   \n",
       "4  10001010       0.0      8.0      0.0       NaN      NaN      NaN      NaN   \n",
       "\n",
       "   S1COHBYR  S1HRSAMP  ...  R8LBSATWLF  R9LBSATWLF  R10LBSATWLF  R11LBSATWLF  \\\n",
       "0       NaN       NaN  ...         NaN         NaN          NaN          NaN   \n",
       "1       NaN       NaN  ...         NaN         NaN          NaN          NaN   \n",
       "2       3.0       1.0  ...         5.4         NaN          6.4          NaN   \n",
       "3       3.0       1.0  ...         4.6         NaN          4.2          NaN   \n",
       "4       NaN       NaN  ...         NaN         2.8          NaN          4.8   \n",
       "\n",
       "   R12LBSATWLF  R13LBSATWLF  R14LBSATWLF  R15LBSATWLF  R16LBSATWLF  FILEVER  \n",
       "0          NaN          NaN          NaN          NaN          NaN        X  \n",
       "1          NaN          NaN          NaN          NaN          NaN        X  \n",
       "2          NaN          NaN          NaN          NaN          NaN        X  \n",
       "3          2.4          NaN          NaN          NaN          NaN        X  \n",
       "4          NaN          NaN          NaN          NaN          NaN        X  \n",
       "\n",
       "[5 rows x 19880 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_stata('data/extracted/randhrs1992_2022v1.dta', convert_categoricals=False)\n",
    "# df.to_parquet('data/extracted/randhrs1992_2022v1.parquet')\n",
    "# df.columns = df.columns.str.upper()\n",
    "df = pd.read_parquet('data/extracted/randhrs1992_2022v1.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6e22373-5613-4325-94f2-02b4150abe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVE_YEARS = {\n",
    "    1: 1992,  # HRS cohort entry\n",
    "    2: 1993,  # AHEAD cohort entry (off-year)\n",
    "    3: 1994,  # Off-year\n",
    "    4: 1995,  # Off-year\n",
    "    5: 1996,  # Biennial pattern begins\n",
    "    6: 1998,  # CODA/WB cohorts enter\n",
    "    7: 2000,\n",
    "    8: 2002,\n",
    "    9: 2004,  # Early Baby Boomer cohort enters\n",
    "    10: 2006,\n",
    "    11: 2008,\n",
    "    12: 2010, # Mid Baby Boomer cohort enters\n",
    "    13: 2012,\n",
    "    14: 2014,\n",
    "    15: 2016, # Late Baby Boomer cohort enters\n",
    "    16: 2018,\n",
    "    17: 2020, # COVID wave\n",
    "    18: 2022  # Early Generation X cohort enters\n",
    "}\n",
    "\n",
    "def get_wave_year(wave: int) -> int | float:\n",
    "    return WAVE_YEARS.get(wave, np.nan)\n",
    "\n",
    "def get_variable_name(wave: int, var_base: str) -> str:\n",
    "    return f\"R{wave}{var_base}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8d8239f-2054-4497-a6a2-b7157397e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wave_features(df: pd.DataFrame, wave: int, lags: int = 2):\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # Base identifiers\n",
    "    data['person_id'] = df['HHIDPN']\n",
    "    data['wave'] = wave\n",
    "    data['calendar_year'] = WAVE_YEARS[wave]\n",
    "\n",
    "    # Demographics\n",
    "    birth_year = pd.to_numeric(df['RABYEAR'], errors='coerce')\n",
    "    age = WAVE_YEARS[wave] - birth_year # pyright: ignore[reportOperatorIssue]\n",
    "\n",
    "    data['birth_year'] = birth_year\n",
    "    data['age'] = age\n",
    "    data['age_squared'] = age ** 2\n",
    "\n",
    "    data['female'] = (pd.to_numeric(df['RAGENDER'], errors='coerce') == 2)\n",
    "\n",
    "\n",
    "    # data['white'] = (pd.to_numeric(df['RARACEM'], errors='coerce') == 1)\n",
    "    # data['black'] = (pd.to_numeric(df['RARACEM'], errors='coerce') == 2)\n",
    "    # data['hispanic'] = (pd.to_numeric(df['RAHISPAN'], errors='coerce') == 1)\n",
    "\n",
    "    race = pd.to_numeric(df['RARACEM'], errors='coerce')\n",
    "    hisp = pd.to_numeric(df['RAHISPAN'], errors='coerce')\n",
    "\n",
    "    def map_ethnicity(r, h):\n",
    "        if h == 1:\n",
    "            return \"Hispanic\"\n",
    "        elif r == 1:\n",
    "            return \"White\"\n",
    "        elif r == 2:\n",
    "            return \"Black\"\n",
    "        else:\n",
    "            return \"Other\"\n",
    "\n",
    "    data['ethnicity'] = pd.Categorical(\n",
    "        [map_ethnicity(r, h) for r, h in zip(race, hisp)],\n",
    "        categories=[\"White\", \"Black\", \"Hispanic\", \"Other\"]\n",
    "    )\n",
    "\n",
    "    data['education_years'] = pd.to_numeric(df['RAEDUC'], errors='coerce')\n",
    "    data['college_plus'] = (pd.to_numeric(df['RAEDEGRM'], errors='coerce') >= 4)  # pyright: ignore[reportOperatorIssue]\n",
    "\n",
    "    variables = {\n",
    "        'self_rated_health': 'SHLT',\n",
    "        'bmi': 'BMI',\n",
    "        'weight': 'WEIGHT',\n",
    "        'height': 'HEIGHT',\n",
    "        'mobility_limitations': 'MOBILA',\n",
    "        'large_muscle_limitations': 'LGMUSA',\n",
    "        'adl_limitations': 'ADL5A',\n",
    "        'iadl_limitations': 'IADL5A',\n",
    "        'fine_motor_limitations': 'FINEA',\n",
    "        'cognition_score': 'COG27',\n",
    "        'memory_recall': 'TR20',\n",
    "        'immediate_recall': 'IMRC',\n",
    "        'delayed_recall': 'DLRC',\n",
    "        'serial7': 'SER7',\n",
    "        'depression_score': 'CESD',\n",
    "        'felt_depressed': 'DEPRES',\n",
    "        'everything_effort': 'EFFORT',\n",
    "        'restless_sleep': 'SLEEPR',\n",
    "        'felt_lonely': 'FLONE',\n",
    "        'ever_smoked': 'SMOKEV',\n",
    "        'current_smoker': 'SMOKEN',\n",
    "        'drinks_per_day': 'DRINKD',\n",
    "        'drink_days_per_week': 'DRINKN',\n",
    "        'vigorous_activity': 'VIGACT',\n",
    "        'marital_status': 'MSTAT'\n",
    "    }\n",
    "\n",
    "    # Loop from 0 to lags\n",
    "    for lag in range(lags + 1):\n",
    "        w = wave - lag\n",
    "        if w < 1:\n",
    "            continue\n",
    "\n",
    "        suffix = f\"_lag{lag}\" if lag > 0 else \"\"\n",
    "\n",
    "        for name, code in variables.items():\n",
    "            col = f'R{w}{code}'\n",
    "            data[f'{name}{suffix}'] = pd.to_numeric(df.get(col), errors='raise')\n",
    "\n",
    "    features = pd.DataFrame(data)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1c52e38-95bd-43ec-a811-d354a965e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add simplified temporal features suitable for a screening app.\n",
    "    Uses first differences (current - lag1).\n",
    "    Avoids DataFrame fragmentation by concatenating once.\n",
    "    \"\"\"\n",
    "\n",
    "    new_features = {}\n",
    "\n",
    "    # =====================================================\n",
    "    # BMI & WEIGHT\n",
    "    # =====================================================\n",
    "    new_features['bmi_change'] = df['bmi'] - df['bmi_lag1']\n",
    "    new_features['weight_change_kg'] = df['weight'] - df['weight_lag1']\n",
    "\n",
    "    # Safe percent change (avoid division by zero)\n",
    "    new_features['weight_change_pct'] = np.where(\n",
    "        df['weight_lag1'] != 0,\n",
    "        (new_features['weight_change_kg'] / df['weight_lag1']) * 100,\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    new_features['obese'] = (df['bmi'] >= 30).astype(int)\n",
    "    new_features['overweight'] = ((df['bmi'] >= 25) & (df['bmi'] < 30)).astype(int)\n",
    "    new_features['rapid_weight_gain'] = (new_features['bmi_change'] > 1).astype(int)\n",
    "    new_features['rapid_weight_loss'] = (new_features['bmi_change'] < -1).astype(int)\n",
    "\n",
    "    # =====================================================\n",
    "    # SELF-RATED HEALTH\n",
    "    # =====================================================\n",
    "    new_features['health_change'] = df['self_rated_health'] - df['self_rated_health_lag1']\n",
    "    new_features['health_worsening'] = (new_features['health_change'] > 0).astype(int)\n",
    "    new_features['health_crash'] = (new_features['health_change'] >= 2).astype(int)\n",
    "\n",
    "    # =====================================================\n",
    "    # FUNCTIONAL STATUS\n",
    "    # =====================================================\n",
    "    new_features['mobility_change'] = df['mobility_limitations'] - df['mobility_limitations_lag1']\n",
    "    new_features['mobility_worsening'] = (new_features['mobility_change'] > 0).astype(int)\n",
    "    new_features['new_mobility_problem'] = (\n",
    "        (df['mobility_limitations'] > 0) &\n",
    "        (df['mobility_limitations_lag1'] == 0)\n",
    "    ).astype(int)\n",
    "    new_features['any_mobility_limitation'] = (df['mobility_limitations'] > 0).astype(int)\n",
    "\n",
    "    new_features['adl_change'] = df['adl_limitations'] - df['adl_limitations_lag1']\n",
    "    new_features['adl_worsening'] = (new_features['adl_change'] > 0).astype(int)\n",
    "    new_features['any_adl_limitation'] = (df['adl_limitations'] > 0).astype(int)\n",
    "\n",
    "    new_features['iadl_change'] = df['iadl_limitations'] - df['iadl_limitations_lag1']\n",
    "    new_features['any_iadl_limitation'] = (df['iadl_limitations'] > 0).astype(int)\n",
    "\n",
    "    # =====================================================\n",
    "    # COGNITION\n",
    "    # =====================================================\n",
    "    new_features['cognition_change'] = df['cognition_score_lag1'] - df['cognition_score']\n",
    "    new_features['cognition_worsening'] = (new_features['cognition_change'] > 0).astype(int)\n",
    "    new_features['low_cognition'] = (df['cognition_score'] < 12).astype(int)\n",
    "\n",
    "    new_features['memory_change'] = df['memory_recall_lag1'] - df['memory_recall']\n",
    "    new_features['memory_worsening'] = (new_features['memory_change'] > 0).astype(int)\n",
    "\n",
    "    # =====================================================\n",
    "    # MENTAL HEALTH\n",
    "    # =====================================================\n",
    "    new_features['depression_change'] = df['depression_score'] - df['depression_score_lag1']\n",
    "    new_features['depression_worsening'] = (new_features['depression_change'] > 0).astype(int)\n",
    "    new_features['elevated_depression'] = (df['depression_score'] >= 3).astype(int)\n",
    "    new_features['chronic_depression'] = (\n",
    "        (df['depression_score'] >= 3) &\n",
    "        (df['depression_score_lag1'] >= 3)\n",
    "    ).astype(int)\n",
    "\n",
    "    # =====================================================\n",
    "    # HEALTH BEHAVIORS\n",
    "    # =====================================================\n",
    "\n",
    "    new_features['sleep_problem'] = (df['restless_sleep'] == 1).astype(int)\n",
    "\n",
    "    new_features['sleep_change'] = df['restless_sleep'] - df['restless_sleep_lag1']\n",
    "\n",
    "    new_features['new_sleep_problem'] = (\n",
    "        (df['restless_sleep'] == 1) &\n",
    "        (df['restless_sleep_lag1'] == 0)\n",
    "    ).astype(int)\n",
    "    \n",
    "    new_features['former_smoker'] = (\n",
    "        (df['ever_smoked'] == 1) &\n",
    "        (df['current_smoker'] == 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    new_features['quit_smoking'] = (\n",
    "        (df['current_smoker'] == 0) &\n",
    "        (df['current_smoker_lag1'] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    new_features['sedentary'] = (df['vigorous_activity'] == 0).astype(int)\n",
    "    new_features['stopped_activity'] = (\n",
    "        (df['vigorous_activity'] == 0) &\n",
    "        (df['vigorous_activity_lag1'] == 1)\n",
    "    ).astype(int)\n",
    "\n",
    "    new_features['drinks_per_week'] = df['drinks_per_day'] * df['drink_days_per_week']\n",
    "    new_features['heavy_drinking'] = (new_features['drinks_per_week'] > 14).astype(int)\n",
    "\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0676c07-764f-4c75-afb4-144d2f42cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_map = {\n",
    "    'diabetes': 'DIABE',\n",
    "    'cvd': 'HEARTE', # cardiovascular disease\n",
    "    'stroke': 'STROKE',\n",
    "    'lung': 'LUNGE',\n",
    "    'cancer': 'CANCRE',\n",
    "    'hibp': 'HIBPE', # high blood preasure \n",
    "    'arthritis': 'ARTHRE',\n",
    "    \"psychiatric\": \"PSYCHE\",  # Psychiatric problems\n",
    "    \"memory\":      \"MEMRYE\",\n",
    "}\n",
    "\n",
    "def create_targets(df: pd.DataFrame, feature_wave: int, outcome_wave: int):\n",
    "\n",
    "    new_targets = {}\n",
    "    new_targets['person_id'] = df['HHIDPN']\n",
    "\n",
    "    for target_name, code in disease_map.items():\n",
    "        baseline_col = f'R{feature_wave}{code}'\n",
    "        outcome_col = f'R{outcome_wave}{code}'\n",
    "\n",
    "        if baseline_col in df.columns and outcome_col in df.columns:\n",
    "            no_disease_baseline = df[baseline_col] == 0\n",
    "            develops_disease = df[outcome_col] == 1\n",
    "\n",
    "            target_values = (no_disease_baseline & develops_disease).astype(float)\n",
    "            target_values[df[outcome_col].isna()] = np.nan\n",
    "\n",
    "            new_targets[f'target_{target_name}'] = target_values\n",
    "            new_targets[f'eligible_{target_name}'] = no_disease_baseline.astype(int)\n",
    "\n",
    "    # Single DataFrame creation → no fragmentation\n",
    "    targets = pd.DataFrame(new_targets, index=df.index)\n",
    "\n",
    "    return targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15d12b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking Disease Columns ===\n",
      "✅ diabetes     R5DIABE         exists, n=19,578\n",
      "✅ cvd          R5HEARTE        exists, n=19,578\n",
      "✅ stroke       R5STROKE        exists, n=19,578\n",
      "✅ lung         R5LUNGE         exists, n=19,578\n",
      "✅ cancer       R5CANCRE        exists, n=19,578\n",
      "✅ hibp         R5HIBPE         exists, n=19,578\n",
      "✅ arthritis    R5ARTHRE        exists, n=19,578\n",
      "✅ psychiatric  R5PSYCHE        exists, n=19,578\n",
      "✅ memory       R5MEMRYE        exists, n=19,578\n"
     ]
    }
   ],
   "source": [
    "# Add to your data processing notebook\n",
    "print(\"\\n=== Checking Disease Columns ===\")\n",
    "for disease, code in disease_map.items():\n",
    "    # Check wave 5 as example\n",
    "    col = f'R5{code}'\n",
    "    exists = col in df.columns\n",
    "    if exists:\n",
    "        count = df[col].notna().sum()\n",
    "        print(f\"✅ {disease:12} {col:15} exists, n={count:,}\")\n",
    "    else:\n",
    "        print(f\"❌ {disease:12} {col:15} NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4411d5e3-c4e0-4052-ad01-9be42b3d9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    df: pd.DataFrame, \n",
    "    feature_waves: List[int], \n",
    "    prediction_horizon: int = 2, \n",
    "    target: str = 'diabetes'\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a modeling dataset for a specific disease target.\n",
    "    \"\"\"\n",
    "    # Ensure standard naming convention\n",
    "    if 'hhidpn' in df.columns:\n",
    "        df.columns = df.columns.str.upper()\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    for wave in feature_waves:\n",
    "        outcome_wave = wave + prediction_horizon\n",
    "        if outcome_wave > 16:\n",
    "            continue\n",
    "        \n",
    "        # 1. Extract wave features and add temporal math (lags, velocity)\n",
    "        feats = extract_wave_features(df, wave)\n",
    "        feats = add_temporal_features(feats)\n",
    "        \n",
    "        # 2. Create target and eligibility flags for this specific horizon\n",
    "        targs = create_targets(df, wave, outcome_wave)\n",
    "        \n",
    "        # 3. Join features and targets on unique ID\n",
    "        combined = feats.merge(targs, on='person_id', how='inner')\n",
    "        all_data.append(combined)\n",
    "    \n",
    "    # Combine all selected waves into one master dataframe\n",
    "    dataset = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    \n",
    "    # --- FILTERING FOR THE SPECIFIC TARGET ---\n",
    "    eligible_col = f'eligible_{target}'\n",
    "    target_col = f'target_{target}'\n",
    "    \n",
    "    # Only keep people who did NOT have the disease at the feature wave\n",
    "    dataset = dataset[dataset[eligible_col] == 1].copy()\n",
    "    \n",
    "    # Remove rows where the outcome is unknown (NaN)\n",
    "    dataset = dataset[pd.notna(dataset[target_col])].copy()\n",
    "    \n",
    "    # --- FEATURE SELECTION ---\n",
    "    # We must exclude ID, metadata, and ALL target/eligible flags to prevent leakage\n",
    "    exclude_prefixes = ('target_', 'eligible_')\n",
    "    metadata_cols = [\n",
    "        # 'person_id', \n",
    "        'wave', \n",
    "        # 'wave_year'\n",
    "    ]\n",
    "    # person id is important, wave year also\n",
    "    \n",
    "    feature_cols = [c for c in dataset.columns \n",
    "                    if not c.startswith(exclude_prefixes) \n",
    "                    and c not in metadata_cols]\n",
    "\n",
    "    X = dataset[feature_cols].copy()\n",
    "    y = dataset[target_col].copy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c31edc3-d8c6-4a06-9a2d-aac1ecfa4bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset for diabetes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes: shape = (99591, 122), positives = 6493.0, saved to data/processed/randhrs_diabetes_4yr.csv & data/processed/randhrs_diabetes_4yr.parquet\n",
      "\n",
      "Creating dataset for cvd...\n",
      "cvd: shape = (97871, 122), positives = 8020.0, saved to data/processed/randhrs_cvd_4yr.csv & data/processed/randhrs_cvd_4yr.parquet\n",
      "\n",
      "Creating dataset for stroke...\n",
      "stroke: shape = (113886, 122), positives = 3976.0, saved to data/processed/randhrs_stroke_4yr.csv & data/processed/randhrs_stroke_4yr.parquet\n",
      "\n",
      "Creating dataset for lung...\n",
      "lung: shape = (113082, 122), positives = 3811.0, saved to data/processed/randhrs_lung_4yr.csv & data/processed/randhrs_lung_4yr.parquet\n",
      "\n",
      "Creating dataset for cancer...\n",
      "cancer: shape = (107492, 122), positives = 5032.0, saved to data/processed/randhrs_cancer_4yr.csv & data/processed/randhrs_cancer_4yr.parquet\n",
      "\n",
      "Creating dataset for hibp...\n",
      "hibp: shape = (58085, 122), positives = 10302.0, saved to data/processed/randhrs_hibp_4yr.csv & data/processed/randhrs_hibp_4yr.parquet\n",
      "\n",
      "Creating dataset for arthritis...\n",
      "arthritis: shape = (56313, 122), positives = 9663.0, saved to data/processed/randhrs_arthritis_4yr.csv & data/processed/randhrs_arthritis_4yr.parquet\n",
      "\n",
      "Creating dataset for psychiatric...\n",
      "psychiatric: shape = (104472, 122), positives = 4659.0, saved to data/processed/randhrs_psychiatric_4yr.csv & data/processed/randhrs_psychiatric_4yr.parquet\n",
      "\n",
      "Creating dataset for memory...\n",
      "memory: shape = (45704, 122), positives = 1577.0, saved to data/processed/randhrs_memory_4yr.csv & data/processed/randhrs_memory_4yr.parquet\n"
     ]
    }
   ],
   "source": [
    "feature_waves = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "prediction_horizon = 2  # 4 years\n",
    "\n",
    "years = prediction_horizon * 2\n",
    "save_dir = \"data/processed\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for disease in disease_map.keys():\n",
    "\n",
    "    print(f\"\\nCreating dataset for {disease}...\")\n",
    "\n",
    "    X, y = create_dataset(\n",
    "        df=df,\n",
    "        feature_waves=feature_waves,\n",
    "        prediction_horizon=prediction_horizon,\n",
    "        target=disease\n",
    "    )\n",
    "\n",
    "    # Ensure y is a Series\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        y = y.iloc[:, 0]\n",
    "\n",
    "    target_name = f\"incident_{disease}_{years}yr\"\n",
    "\n",
    "    dataset = pd.concat(\n",
    "        [\n",
    "            X.reset_index(drop=True),\n",
    "            y.reset_index(drop=True).rename(target_name)\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # File paths\n",
    "    csv_path = os.path.join(save_dir, f\"randhrs_{disease}_{years}yr.csv\")\n",
    "    parquet_path = os.path.join(save_dir, f\"randhrs_{disease}_{years}yr.parquet\")\n",
    "\n",
    "    # Save CSV\n",
    "    dataset.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Save Parquet\n",
    "    dataset.to_parquet(parquet_path, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"{disease}: shape = {dataset.shape}, \"\n",
    "        f\"positives = {dataset[target_name].sum()}, \"\n",
    "        f\"saved to {csv_path} & {parquet_path}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
