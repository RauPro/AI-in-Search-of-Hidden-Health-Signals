{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════╗\n",
    "║  HYBRID DISEASE-EXPERT ENSEMBLE                                          ║\n",
    "║  Health Hackathon — Disease Onset Prediction                             ║\n",
    "║                                                                          ║\n",
    "║  Combines:                                                               ║\n",
    "║    ✓ Disease-specific expert models (1 per disease)                      ║\n",
    "║    ✓ Temporal feature engineering (deltas, acceleration, rolling stats)  ║\n",
    "║    ✓ Group-aware splitting (no person leakage)                           ║\n",
    "║    ✓ 4-year prediction horizon                                           ║\n",
    "║    ✓ SHAP explainability + fairness audit                                ║\n",
    "╚══════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import traceback\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score, roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Config ──────────────────────────────────────────────────────────────\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH  = Path.cwd() / \"data\" / \"extracted\" / \"randhrs1992_2022v1.parquet\"\n",
    "OUTPUT_DIR = Path.cwd() / \"output_hybrid\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Screenings where we measure features → outcome is screening + HORIZON\n",
    "FEATURE_SCREENINGS = list(range(5, 13))   # HRS screenings 5..12\n",
    "PREDICTION_HORIZON = 2                    # 2 screenings ahead (~4 years)\n",
    "LAGS = 2                                  # use current, prev, prev-prev screening\n",
    "\n",
    "# 8 disease experts — screening-specific self-report codes (NOT cumulative \"E\" vars)\n",
    "DISEASE_MAP = {\n",
    "    \"diabetes\":    \"DIAB\",\n",
    "    \"cvd\":         \"HEART\",\n",
    "    \"stroke\":      \"STROK\",\n",
    "    \"lung\":        \"LUNG\",\n",
    "    \"cancer\":      \"CANCR\",\n",
    "    \"hibp\":        \"HIBP\",\n",
    "    \"arthritis\":   \"ARTHR\",\n",
    "    \"psychiatric\": \"PSYCH\",\n",
    "    \"memory\":      \"MEMRY\",\n",
    "}\n",
    "\n",
    "# ── Variables to extract per screening ──────────────────────────────\n",
    "\n",
    "SCREENING_VARS = {\n",
    "    \"self_rated_health\": \"SHLT\",\n",
    "    \"bmi\":               \"BMI\",\n",
    "    \"weight\":            \"WEIGHT\",\n",
    "    \"height\":            \"HEIGHT\",\n",
    "    \"mobility\":          \"MOBILA\",\n",
    "    \"gross_motor\":       \"GROSSA\",\n",
    "    \"large_muscle\":      \"LGMUSA\",\n",
    "    \"fine_motor\":        \"FINEA\",\n",
    "    \"adl\":               \"ADL5A\",\n",
    "    \"iadl\":              \"IADL5A\",\n",
    "    \"cognition\":         \"COG27\",\n",
    "    \"memory_recall\":     \"TR20\",\n",
    "    \"immediate_recall\":  \"IMRC\",\n",
    "    \"delayed_recall\":    \"DLRC\",\n",
    "    \"serial7\":           \"SER7\",\n",
    "    \"cesd\":              \"CESD\",\n",
    "    \"depressed\":         \"DEPRES\",\n",
    "    \"effort\":            \"EFFORT\",\n",
    "    \"restless_sleep\":    \"SLEEPR\",\n",
    "    \"lonely\":            \"FLONE\",\n",
    "    \"ever_smoked\":       \"SMOKEV\",\n",
    "    \"current_smoker\":    \"SMOKEN\",\n",
    "    \"drinks_per_day\":    \"DRINKD\",\n",
    "    \"drink_days_week\":   \"DRINKN\",\n",
    "    \"vigorous_activity\": \"VGACTX\",\n",
    "    \"marital_status\":    \"MSTAT\",\n",
    "    \"condition_count\":   \"CONDE\",\n",
    "    \"self_health_comp\":  \"SHLTC\",\n",
    "    \"out_of_pocket\":     \"OOPMD\",\n",
    "    \"working\":           \"WORK\",\n",
    "}\n",
    "\n",
    "# ── Helpers ──────────────────────────────────────────────────────────\n",
    "\n",
    "# HRS screening → approximate year (fallback when interview date missing)\n",
    "SCREENING_YEARS = {\n",
    "    1:1992, 2:1993, 3:1994, 4:1995, 5:1996, 6:1998, 7:2000,\n",
    "    8:2002, 9:2004, 10:2006, 11:2008, 12:2010, 13:2012,\n",
    "    14:2014, 15:2016, 16:2018, 17:2020, 18:2022\n",
    "}\n",
    "\n",
    "def banner(msg):\n",
    "    print(f\"\\n{'='*65}\\n  {msg}\\n{'='*65}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 1: EXTRACT FEATURES PER SCREENING (with lags)\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def extract_screening_features(df_raw: pd.DataFrame, scr: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a given screening, extract:\n",
    "      - Demographics (static)\n",
    "      - Current screening values\n",
    "      - Lag-1 and Lag-2 values (raw)\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    # Person identifier\n",
    "    data[\"person_id\"] = df_raw[\"HHIDPN\"].values\n",
    "\n",
    "    # Screening date (interview midpoint: SAS date = days since 1960-01-01)\n",
    "    SAS_EPOCH = pd.Timestamp(\"1960-01-01\")\n",
    "    iw_col = f\"R{scr}IWMID\"\n",
    "    if iw_col in df_raw.columns:\n",
    "        iw_days = pd.to_numeric(df_raw[iw_col], errors=\"coerce\")\n",
    "        screening_date = SAS_EPOCH + pd.to_timedelta(iw_days, unit=\"D\")\n",
    "        data[\"screening_year\"]  = screening_date.dt.year.values.astype(float)\n",
    "        data[\"screening_month\"] = screening_date.dt.month.values.astype(float)\n",
    "    else:\n",
    "        data[\"screening_year\"]  = float(SCREENING_YEARS[scr])\n",
    "        data[\"screening_month\"] = np.nan\n",
    "\n",
    "    # Time gap to previous screening (in years)\n",
    "    iw_lag1_col = f\"R{scr - 1}IWMID\" if scr > 1 else None\n",
    "    if iw_lag1_col and iw_lag1_col in df_raw.columns and iw_col in df_raw.columns:\n",
    "        iw_cur  = pd.to_numeric(df_raw[iw_col], errors=\"coerce\")\n",
    "        iw_prev = pd.to_numeric(df_raw[iw_lag1_col], errors=\"coerce\")\n",
    "        data[\"years_since_last_screening\"] = ((iw_cur - iw_prev) / 365.25).values\n",
    "    else:\n",
    "        data[\"years_since_last_screening\"] = np.nan\n",
    "\n",
    "    # Static demographics — age from actual screening date\n",
    "    birth_year = pd.to_numeric(df_raw[\"RABYEAR\"], errors=\"coerce\")\n",
    "    age = data[\"screening_year\"] - birth_year.values\n",
    "    data[\"birth_year\"] = birth_year.values\n",
    "    data[\"age\"] = age\n",
    "    data[\"age_squared\"] = age ** 2\n",
    "\n",
    "    data[\"female\"]    = (pd.to_numeric(df_raw[\"RAGENDER\"], errors=\"coerce\") == 2).astype(int).values\n",
    "\n",
    "    race = pd.to_numeric(df_raw[\"RARACEM\"], errors=\"coerce\")\n",
    "    hisp = pd.to_numeric(df_raw[\"RAHISPAN\"], errors=\"coerce\")\n",
    "    def map_ethnicity(r, h):\n",
    "        if h == 1:\n",
    "            return \"Hispanic\"\n",
    "        if r == 1:\n",
    "            return \"White\"\n",
    "        if r == 2:\n",
    "            return \"Black\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    data[\"ethnicity\"] = pd.Categorical(\n",
    "        [map_ethnicity(r, h) for r, h in zip(race, hisp)],\n",
    "        categories=[\"White\", \"Black\", \"Hispanic\", \"Other\"]\n",
    "    )\n",
    "    \n",
    "    data[\"education\"] = pd.to_numeric(df_raw.get(\"RAEDYRS\"), errors=\"coerce\").values\n",
    "    data[\"edu_cat\"]   = pd.to_numeric(df_raw.get(\"RAEDUC\"), errors=\"coerce\").values\n",
    "    data[\"degree\"]    = pd.to_numeric(df_raw.get(\"RAEDEGRM\"), errors=\"coerce\").values\n",
    "\n",
    "    # Screening / lag extraction\n",
    "    for lag in range(LAGS + 1):\n",
    "        w = scr - lag\n",
    "        if w < 1:\n",
    "            continue\n",
    "        suffix = f\"_lag{lag}\" if lag > 0 else \"\"\n",
    "        for name, code in SCREENING_VARS.items():\n",
    "            col = f\"R{w}{code}\"\n",
    "            if col in df_raw.columns:\n",
    "                data[f\"{name}{suffix}\"] = pd.to_numeric(df_raw[col], errors=\"coerce\").values\n",
    "            else:\n",
    "                data[f\"{name}{suffix}\"] = np.nan\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 2: TEMPORAL FEATURE ENGINEERING\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add velocity, acceleration, decline, and interaction features.\"\"\"\n",
    "    new = {}\n",
    "\n",
    "    # ── BMI trajectories (delta between screenings) ──\n",
    "    new[\"bmi_delta_lag1\"]    = df.get(\"bmi\", np.nan) - df.get(\"bmi_lag1\", np.nan)\n",
    "    new[\"bmi_delta_lag2\"]    = df.get(\"bmi\", np.nan) - df.get(\"bmi_lag2\", np.nan)\n",
    "    new[\"bmi_accel\"]         = new[\"bmi_delta_lag1\"] - (\n",
    "        df.get(\"bmi_lag1\", np.nan) - df.get(\"bmi_lag2\", np.nan)\n",
    "    )\n",
    "    new[\"weight_change_kg\"]  = df.get(\"weight\", np.nan) - df.get(\"weight_lag1\", np.nan)\n",
    "    wl1 = df.get(\"weight_lag1\", np.nan)\n",
    "    new[\"weight_change_pct\"] = np.where(wl1 != 0, new[\"weight_change_kg\"] / wl1 * 100, np.nan)\n",
    "    new[\"obese\"]             = (df.get(\"bmi\", 0) >= 30).astype(int)\n",
    "    new[\"overweight\"]        = ((df.get(\"bmi\", 0) >= 25) & (df.get(\"bmi\", 0) < 30)).astype(int)\n",
    "    new[\"rapid_weight_gain\"] = (new[\"bmi_delta_lag1\"] > 1).astype(int)\n",
    "    new[\"rapid_weight_loss\"] = (new[\"bmi_delta_lag1\"] < -1).astype(int)\n",
    "\n",
    "    # ── Health perception ──\n",
    "    new[\"health_decline_lag1\"] = df.get(\"self_rated_health\", np.nan) - df.get(\"self_rated_health_lag1\", np.nan)\n",
    "    new[\"health_decline_lag2\"] = df.get(\"self_rated_health\", np.nan) - df.get(\"self_rated_health_lag2\", np.nan)\n",
    "    new[\"health_worsening\"]    = (new[\"health_decline_lag1\"] > 0).astype(int)\n",
    "    new[\"health_crash\"]        = (new[\"health_decline_lag1\"] >= 2).astype(int)\n",
    "\n",
    "    # ── Functional decline ──\n",
    "    for base in [\"mobility\", \"adl\", \"iadl\"]:\n",
    "        cur = df.get(base, np.nan)\n",
    "        lag1 = df.get(f\"{base}_lag1\", np.nan)\n",
    "        new[f\"{base}_decline_lag1\"] = cur - lag1\n",
    "        new[f\"{base}_worsening\"]    = (new[f\"{base}_decline_lag1\"] > 0).astype(int)\n",
    "        new[f\"new_{base}_problem\"]  = ((cur > 0) & (lag1 == 0)).astype(int)\n",
    "        new[f\"any_{base}\"]          = (cur > 0).astype(int)\n",
    "\n",
    "    # ── Cognitive decline ──\n",
    "    cog    = df.get(\"cognition\", np.nan)\n",
    "    cog_l1 = df.get(\"cognition_lag1\", np.nan)\n",
    "    cog_l2 = df.get(\"cognition_lag2\", np.nan)\n",
    "    new[\"cog_decline_lag1\"]    = cog_l1 - cog\n",
    "    new[\"cog_decline_lag2\"]    = cog_l2 - cog\n",
    "    new[\"cog_worsening\"]       = (new[\"cog_decline_lag1\"] > 0).astype(int)\n",
    "    new[\"sharp_cog_drop\"]      = (new[\"cog_decline_lag1\"] > 3).astype(int)\n",
    "    new[\"low_cognition\"]       = (cog < 12).astype(int)\n",
    "\n",
    "    mem    = df.get(\"memory_recall\", np.nan)\n",
    "    mem_l1 = df.get(\"memory_recall_lag1\", np.nan)\n",
    "    new[\"memory_decline_lag1\"] = mem_l1 - mem\n",
    "    new[\"memory_worsening\"]    = (new[\"memory_decline_lag1\"] > 0).astype(int)\n",
    "\n",
    "    # ── Mental health ──\n",
    "    cesd    = df.get(\"cesd\", np.nan)\n",
    "    cesd_l1 = df.get(\"cesd_lag1\", np.nan)\n",
    "    new[\"cesd_increase\"]        = cesd - cesd_l1\n",
    "    new[\"cesd_worsening\"]       = (new[\"cesd_increase\"] > 0).astype(int)\n",
    "    new[\"elevated_depression\"]  = (cesd >= 3).astype(int)\n",
    "    new[\"high_depression\"]      = (cesd >= 4).astype(int)\n",
    "    new[\"chronic_depression\"]   = ((cesd >= 3) & (cesd_l1 >= 3)).astype(int)\n",
    "\n",
    "    # ── Health behaviors ──\n",
    "    new[\"former_smoker\"]  = ((df.get(\"ever_smoked\", 0) == 1) & (df.get(\"current_smoker\", 0) == 0)).astype(int)\n",
    "    new[\"quit_smoking\"]   = ((df.get(\"current_smoker\", 0) == 0) & (df.get(\"current_smoker_lag1\", 0) == 1)).astype(int)\n",
    "    dpd = df.get(\"drinks_per_day\", np.nan)\n",
    "    dpw = df.get(\"drink_days_week\", np.nan)\n",
    "    new[\"drinks_per_week\"]  = dpd * dpw\n",
    "    new[\"heavy_drinking\"]   = (new[\"drinks_per_week\"] > 14).astype(int)\n",
    "\n",
    "    # ── Interactions ──\n",
    "    new[\"age_x_bmi\"]             = df.get(\"age\", np.nan) * df.get(\"bmi\", np.nan)\n",
    "    new[\"age_x_cesd\"]            = df.get(\"age\", np.nan) * cesd\n",
    "    new[\"depression_x_mobility\"] = cesd * df.get(\"mobility\", np.nan)\n",
    "    new[\"cog_decline_x_age\"]     = new[\"cog_decline_lag1\"] * df.get(\"age\", np.nan)\n",
    "    new[\"bmi_x_smoking\"]         = df.get(\"bmi\", np.nan) * df.get(\"current_smoker\", np.nan)\n",
    "\n",
    "    # ── Composite scores ──\n",
    "    new[\"metabolic_risk\"] = (\n",
    "        new[\"obese\"] * 2\n",
    "        + (df.get(\"age\", 0) >= 65).astype(int)\n",
    "    )\n",
    "    new[\"frailty_score\"] = (\n",
    "        (df.get(\"mobility\", 0) > 0).astype(int)\n",
    "        + (cesd >= 3).astype(int)\n",
    "        + (new[\"weight_change_pct\"] < -5).astype(int)\n",
    "    )\n",
    "\n",
    "    # Single concat to prevent fragmentation\n",
    "    result = pd.concat([df, pd.DataFrame(new, index=df.index)], axis=1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 3: CREATE DISEASE-SPECIFIC TARGETS\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def create_targets(df_raw: pd.DataFrame, feature_screening: int, outcome_screening: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each disease, create:\n",
    "      - target_{disease}: 1 if onset (0→1) between feature and outcome screening\n",
    "      - eligible_{disease}: 1 if disease=0 at feature screening\n",
    "    Uses screening-specific self-report codes (0=no, 1=yes, 3=disputes, 4=don't know).\n",
    "    Values 3/4 and NaN are treated as missing (excluded from eligibility/outcome).\n",
    "    \"\"\"\n",
    "    targets = {\"person_id\": df_raw[\"HHIDPN\"].values}\n",
    "\n",
    "    for disease_name, code in DISEASE_MAP.items():\n",
    "        baseline_col = f\"R{feature_screening}{code}\"\n",
    "        outcome_col  = f\"R{outcome_screening}{code}\"\n",
    "\n",
    "        if baseline_col in df_raw.columns and outcome_col in df_raw.columns:\n",
    "            baseline = pd.to_numeric(df_raw[baseline_col], errors=\"coerce\")\n",
    "            outcome  = pd.to_numeric(df_raw[outcome_col], errors=\"coerce\")\n",
    "\n",
    "            # Only 0/1 are clean answers; 3 (disputes) and 4 (don't know) → NaN\n",
    "            baseline_clean = baseline.where(baseline.isin([0, 1]))\n",
    "            outcome_clean  = outcome.where(outcome.isin([0, 1]))\n",
    "\n",
    "            no_disease = (baseline_clean == 0)\n",
    "            develops   = (outcome_clean == 1)\n",
    "\n",
    "            target_vals = (no_disease & develops).astype(float)\n",
    "            # Mark as NaN if outcome is unknown\n",
    "            target_vals[outcome_clean.isna()] = np.nan\n",
    "\n",
    "            targets[f\"target_{disease_name}\"]   = target_vals.values\n",
    "            targets[f\"eligible_{disease_name}\"] = no_disease.astype(int).values\n",
    "\n",
    "    return pd.DataFrame(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 4: ASSEMBLE DATASET PER DISEASE\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def build_master_features(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Build multi-screening long-format features + targets.\"\"\"\n",
    "    banner(\"PHASE 1-3: BUILDING FEATURES + TARGETS\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for scr in FEATURE_SCREENINGS:\n",
    "        outcome_scr = scr + PREDICTION_HORIZON\n",
    "        if outcome_scr > 18:\n",
    "            continue\n",
    "\n",
    "        # Features for this screening (with lags)\n",
    "        feats = extract_screening_features(df_raw, scr)\n",
    "        feats = add_temporal_features(feats)\n",
    "\n",
    "        # Targets from this screening → outcome screening\n",
    "        targs = create_targets(df_raw, scr, outcome_scr)\n",
    "\n",
    "        # Merge on person_id\n",
    "        combined = feats.merge(targs, on=\"person_id\", how=\"inner\")\n",
    "        # Internal grouping key (not exposed as a feature)\n",
    "        combined[\"_screening_id\"] = scr\n",
    "        all_data.append(combined)\n",
    "\n",
    "        print(f\"  Screening {scr} → {outcome_scr}: {len(combined):,} rows, \"\n",
    "              f\"{feats.shape[1]} features\")\n",
    "\n",
    "    master = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\n  TOTAL: {len(master):,} rows\")\n",
    "    return master\n",
    "\n",
    "\n",
    "def get_disease_dataset(master: pd.DataFrame, disease: str):\n",
    "    \"\"\"\n",
    "    Filter master to only eligible patients for this disease,\n",
    "    split group-aware, return X_train/test, y_train/test.\n",
    "    \"\"\"\n",
    "    eligible_col = f\"eligible_{disease}\"\n",
    "    target_col   = f\"target_{disease}\"\n",
    "\n",
    "    # Only eligible (didn't have this disease at baseline)\n",
    "    sub = master[master[eligible_col] == 1].copy()\n",
    "    # Remove rows where outcome is unknown\n",
    "    sub = sub[sub[target_col].notna()].copy()\n",
    "    # Drop rows missing critical features\n",
    "    sub = sub.dropna(subset=[\"age\", \"bmi\"])\n",
    "\n",
    "    y = sub[target_col].astype(int)\n",
    "\n",
    "    # Feature columns: exclude targets, eligibility, metadata\n",
    "    exclude_prefixes = (\"target_\", \"eligible_\")\n",
    "    metadata_cols = {\"person_id\", \"_screening_id\"}\n",
    "    # # Also exclude demographic columns used for fairness audit\n",
    "    # fairness_cols = {\"female\", \"ethnicity\"}\n",
    "\n",
    "    feature_cols = sorted([\n",
    "        c for c in sub.columns\n",
    "        if not c.startswith(exclude_prefixes)\n",
    "        and c not in metadata_cols\n",
    "        # Keep fairness cols as features (they can be predictive)\n",
    "    ])\n",
    "\n",
    "    X = sub[feature_cols]\n",
    "\n",
    "    # Group-aware split: same person never in both train and test\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=sub[\"person_id\"]))\n",
    "\n",
    "    X_train = X.iloc[train_idx].copy()\n",
    "    y_train = y.iloc[train_idx].copy()\n",
    "    X_test  = X.iloc[test_idx].copy()\n",
    "    y_test  = y.iloc[test_idx].copy()\n",
    "\n",
    "    # Fairness demographics for test set\n",
    "    demo_test = sub.iloc[test_idx][[\"person_id\", \"female\", \"ethnicity\", \"age\"]].copy()\n",
    "\n",
    "    return feature_cols, X_train, y_train, X_test, y_test, demo_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ═════════════════════════════════════════════════════════════════════\n",
    "# #  PHASE 5: TRAIN EXPERT MODEL FOR ONE DISEASE\n",
    "# # ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "# def train_disease_expert(\n",
    "#     disease: str,\n",
    "#     feature_cols: List[str],\n",
    "#     X_train: pd.DataFrame,\n",
    "#     y_train: pd.Series,\n",
    "#     X_test: pd.DataFrame,\n",
    "#     y_test: pd.Series,\n",
    "# ) -> Tuple[Dict, Dict, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Train LightGBM + CatBoost for one disease, return models, preds, and results.\n",
    "#     \"\"\"\n",
    "#     banner(f\"EXPERT: {disease.upper()}\")\n",
    "\n",
    "#     neg = (y_train == 0).sum()\n",
    "#     pos = (y_train == 1).sum()\n",
    "#     spw = neg / max(pos, 1)\n",
    "#     print(f\"  Train: {len(X_train):,} | Pos: {pos:,} ({pos/(pos+neg):.2%}) | \"\n",
    "#           f\"scale_pos_weight: {spw:.1f}\")\n",
    "\n",
    "#     # Identify categorical columns\n",
    "#     cat_cols = [c for c in feature_cols if X_train[c].dtype.name == \"category\"]\n",
    "#     cat_col_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "#     if cat_cols:\n",
    "#         print(f\"  Categorical features: {cat_cols}\")\n",
    "\n",
    "#     # ── LightGBM ──\n",
    "#     lgb_model = lgb.LGBMClassifier(\n",
    "#         n_estimators=2000,\n",
    "#         learning_rate=0.02,\n",
    "#         num_leaves=63,\n",
    "#         max_depth=7,\n",
    "#         subsample=0.8,\n",
    "#         colsample_bytree=0.7,\n",
    "#         min_child_samples=50,\n",
    "#         scale_pos_weight=spw,\n",
    "#         random_state=SEED,\n",
    "#         n_jobs=-1,\n",
    "#         verbose=-1,\n",
    "#         device=\"cpu\",          # <--- ENABLE GPU\n",
    "#     )\n",
    "#     lgb_model.fit(\n",
    "#         X_train, y_train,\n",
    "#         eval_set=[(X_test, y_test)],\n",
    "#         categorical_feature=cat_cols if cat_cols else \"auto\",\n",
    "#         callbacks=[lgb.early_stopping(300, verbose=False)],\n",
    "#     )\n",
    "#     lgb_pred = lgb_model.predict_proba(X_test)[:, 1]\n",
    "#     lgb_auc = roc_auc_score(y_test, lgb_pred)\n",
    "#     print(f\"  LightGBM  ROC-AUC: {lgb_auc:.4f}\")\n",
    "\n",
    "#     # ── CatBoost ──\n",
    "#     cat_model = CatBoostClassifier(\n",
    "#         iterations=3000,\n",
    "#         learning_rate=0.03,\n",
    "#         depth=6,\n",
    "#         eval_metric=\"AUC\",\n",
    "#         loss_function=\"Logloss\",\n",
    "#         scale_pos_weight=spw,\n",
    "#         random_seed=SEED,\n",
    "#         verbose=0,\n",
    "#         early_stopping_rounds=300,\n",
    "#         use_best_model=True,\n",
    "#         task_type=\"GPU\",       # <--- ENABLE GPU\n",
    "#         devices=\"0\"            # <--- Select GPU 0\n",
    "#     )\n",
    "#     cat_model.fit(\n",
    "#         X_train, y_train,\n",
    "#         eval_set=(X_test, y_test),\n",
    "#         cat_features=cat_col_indices if cat_col_indices else None,\n",
    "#     )\n",
    "#     cat_pred = cat_model.predict_proba(X_test)[:, 1]\n",
    "#     cat_auc = roc_auc_score(y_test, cat_pred)\n",
    "#     print(f\"  CatBoost  ROC-AUC: {cat_auc:.4f}\")\n",
    "\n",
    "#     # ── XGBoost ──\n",
    "#     xgb_model = xgb.XGBClassifier(\n",
    "#         n_estimators=2000,\n",
    "#         learning_rate=0.02,\n",
    "#         max_depth=6,\n",
    "#         subsample=0.8,\n",
    "#         colsample_bytree=0.7,\n",
    "#         min_child_weight=50,\n",
    "#         scale_pos_weight=spw,\n",
    "#         eval_metric=\"auc\",\n",
    "#         enable_categorical=True,\n",
    "#         tree_method=\"hist\",\n",
    "#         random_state=SEED,\n",
    "#         n_jobs=-1,\n",
    "#         verbosity=0,\n",
    "#         early_stopping_rounds=300,\n",
    "#         device=\"cuda\",         # <--- ENABLE GPU (XGBoost 2.0+)\n",
    "#     )\n",
    "    \n",
    "#     xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "#     xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "#     xgb_auc = roc_auc_score(y_test, xgb_pred)\n",
    "#     print(f\"  XGBoost   ROC-AUC: {xgb_auc:.4f}\")\n",
    "\n",
    "#     # ── Average ensemble ──\n",
    "#     avg_pred = (lgb_pred + cat_pred + xgb_pred) / 3\n",
    "#     avg_auc = roc_auc_score(y_test, avg_pred)\n",
    "#     print(f\"  Ensemble  ROC-AUC: {avg_auc:.4f}\")\n",
    "\n",
    "#     models = {\"lgb\": lgb_model, \"cat\": cat_model, \"xgb\": xgb_model}\n",
    "#     preds = {\n",
    "#         \"lgb\": lgb_pred, \"cat\": cat_pred,\n",
    "#         \"xgb\": xgb_pred, \"avg\": avg_pred\n",
    "#     }\n",
    "\n",
    "#     # Evaluate metrics\n",
    "#     results = evaluate_expert(disease, y_test, preds)\n",
    "\n",
    "#     return models, results, avg_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_disease_expert(\n",
    "    disease: str,\n",
    "    feature_cols: List[str],\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    ") -> Tuple[Dict, Dict, np.ndarray]:\n",
    "\n",
    "    banner(f\"EXPERT (Leakage-Safe): {disease.upper()}\")\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # 1️⃣ Class Weight\n",
    "    # ─────────────────────────────────────────────\n",
    "    neg = (y_train == 0).sum()\n",
    "    pos = (y_train == 1).sum()\n",
    "    spw = neg / max(pos, 1)\n",
    "\n",
    "    print(\n",
    "        f\"  Train: {len(X_train):,} | Pos: {pos:,} ({pos/(pos+neg):.2%}) | \"\n",
    "        f\"scale_pos_weight: {spw:.1f}\"\n",
    "    )\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # 2️⃣ Internal Validation Split (NO TEST USED)\n",
    "    # ─────────────────────────────────────────────\n",
    "    splitter = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=0.15, random_state=SEED\n",
    "    )\n",
    "\n",
    "    train_idx, val_idx = next(splitter.split(X_train, y_train))\n",
    "\n",
    "    X_tr = X_train.iloc[train_idx]\n",
    "    y_tr = y_train.iloc[train_idx]\n",
    "    X_val = X_train.iloc[val_idx]\n",
    "    y_val = y_train.iloc[val_idx]\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # 3️⃣ Identify Categorical Columns\n",
    "    # ─────────────────────────────────────────────\n",
    "    cat_cols = [c for c in feature_cols if X_train[c].dtype.name == \"category\"]\n",
    "    cat_col_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "\n",
    "    if cat_cols:\n",
    "        print(f\"  Categorical features: {cat_cols}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # ── LightGBM ──\n",
    "    # =====================================================\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=63,\n",
    "        max_depth=7,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,\n",
    "        min_child_samples=50,\n",
    "        scale_pos_weight=spw,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cpu\", \n",
    "    )\n",
    "\n",
    "    lgb_model.fit(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        categorical_feature=cat_cols if cat_cols else \"auto\",\n",
    "        callbacks=[lgb.early_stopping(300, verbose=False)],\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # ── CatBoost ──\n",
    "    # =====================================================\n",
    "    cat_model = CatBoostClassifier(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=6,\n",
    "        eval_metric=\"AUC\",\n",
    "        loss_function=\"Logloss\",\n",
    "        scale_pos_weight=spw,\n",
    "        random_seed=SEED,\n",
    "        verbose=0,\n",
    "        early_stopping_rounds=300,\n",
    "        use_best_model=True,\n",
    "        task_type=\"GPU\",\n",
    "        devices=\"0\",\n",
    "    )\n",
    "\n",
    "    cat_model.fit(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        eval_set=(X_val, y_val),\n",
    "        cat_features=cat_col_indices if cat_col_indices else None,\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # ── XGBoost ──\n",
    "    # =====================================================\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,\n",
    "        min_child_weight=50,\n",
    "        scale_pos_weight=spw,\n",
    "        eval_metric=\"auc\",\n",
    "        enable_categorical=True,\n",
    "        tree_method=\"hist\",\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "        early_stopping_rounds=300,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # ─────────────────────────────────────────────\n",
    "    # 4️⃣ FINAL EVALUATION ON TRUE TEST SET\n",
    "    # ─────────────────────────────────────────────\n",
    "    lgb_pred = lgb_model.predict_proba(X_test)[:, 1]\n",
    "    cat_pred = cat_model.predict_proba(X_test)[:, 1]\n",
    "    xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    avg_pred = (lgb_pred + cat_pred + xgb_pred) / 3\n",
    "\n",
    "    print(f\"  LightGBM  ROC-AUC: {roc_auc_score(y_test, lgb_pred):.4f}\")\n",
    "    print(f\"  CatBoost  ROC-AUC: {roc_auc_score(y_test, cat_pred):.4f}\")\n",
    "    print(f\"  XGBoost   ROC-AUC: {roc_auc_score(y_test, xgb_pred):.4f}\")\n",
    "    print(f\"  Ensemble  ROC-AUC: {roc_auc_score(y_test, avg_pred):.4f}\")\n",
    "\n",
    "    models = {\"lgb\": lgb_model, \"cat\": cat_model, \"xgb\": xgb_model}\n",
    "    preds = {\n",
    "        \"lgb\": lgb_pred,\n",
    "        \"cat\": cat_pred,\n",
    "        \"xgb\": xgb_pred,\n",
    "        \"avg\": avg_pred,\n",
    "    }\n",
    "\n",
    "    results = evaluate_expert(disease, y_test, preds)\n",
    "\n",
    "    return models, results, avg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 6: EVALUATE & OPTIMIZE THRESHOLD\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def find_best_f2_threshold(y_true, y_proba):\n",
    "    best_t, best_f2 = 0.5, 0\n",
    "    for t in np.linspace(0.02, 0.6, 200):\n",
    "        preds = (y_proba >= t).astype(int)\n",
    "        f2 = fbeta_score(y_true, preds, beta=2, zero_division=0)\n",
    "        if f2 > best_f2:\n",
    "            best_f2 = f2\n",
    "            best_t = t\n",
    "    return best_t, best_f2\n",
    "\n",
    "\n",
    "def evaluate_expert(disease: str, y_test, preds: dict) -> dict:\n",
    "    results = {}\n",
    "    for name, proba in preds.items():\n",
    "        roc  = roc_auc_score(y_test, proba)\n",
    "        pr   = average_precision_score(y_test, proba)\n",
    "        bt, bf2 = find_best_f2_threshold(y_test, proba)\n",
    "\n",
    "        y_pred = (proba >= bt).astype(int)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        results[name] = {\n",
    "            \"roc_auc\": round(roc, 4),\n",
    "            \"pr_auc\": round(pr, 4),\n",
    "            \"f2\": round(bf2, 4),\n",
    "            \"precision\": round(prec, 4),\n",
    "            \"recall\": round(rec, 4),\n",
    "            \"threshold\": round(bt, 4),\n",
    "        }\n",
    "        print(f\"  {disease}/{name}: ROC={roc:.4f} PR={pr:.4f} F2={bf2:.4f} \"\n",
    "              f\"P={prec:.4f} R={rec:.4f} t={bt:.3f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 7: COMBINED \"ANY ONSET\" META-ENSEMBLE\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def build_any_onset_from_experts(\n",
    "    master: pd.DataFrame,\n",
    "    all_models: Dict[str, Dict],\n",
    "    all_feature_cols: Dict[str, List[str]],\n",
    "):\n",
    "    \"\"\"\n",
    "    For the test set, combine expert probabilities:\n",
    "      P(any onset) = 1 - ∏(1 - P_d)  for eligible diseases\n",
    "    \"\"\"\n",
    "    banner(\"META-ENSEMBLE: ANY-DISEASE ONSET\")\n",
    "\n",
    "    # Group by person + screening (using internal _wave key)\n",
    "    # Rebuild predictions disease by disease and combine per person-screening\n",
    "\n",
    "    results_per_ps = {}\n",
    "\n",
    "    for disease, models in all_models.items():\n",
    "        eligible_col = f\"eligible_{disease}\"\n",
    "        target_col   = f\"target_{disease}\"\n",
    "\n",
    "        sub = master[(master[eligible_col] == 1) & (master[target_col].notna())].copy()\n",
    "        sub = sub.dropna(subset=[\"age\", \"bmi\"])\n",
    "\n",
    "        feature_cols = all_feature_cols[disease]\n",
    "        X = sub[feature_cols]\n",
    "\n",
    "        # Get predictions from ensemble mean\n",
    "        lgb_pred = models[\"lgb\"].predict_proba(X)[:, 1]\n",
    "        cat_pred = models[\"cat\"].predict_proba(X)[:, 1]\n",
    "        xgb_pred = models[\"xgb\"].predict_proba(X)[:, 1]\n",
    "        avg_pred = (lgb_pred + cat_pred + xgb_pred) / 3\n",
    "\n",
    "        for i, (pid, w) in enumerate(zip(sub[\"person_id\"].values, sub[\"_screening_id\"].values)):\n",
    "            key = (pid, w)\n",
    "            if key not in results_per_ps:\n",
    "                results_per_ps[key] = {\"probs\": [], \"has_target\": 0, \"any_eligible\": False}\n",
    "            results_per_ps[key][\"probs\"].append(avg_pred[i])\n",
    "            results_per_ps[key][\"any_eligible\"] = True\n",
    "            # Any-onset target: did they develop ANY disease?\n",
    "            if sub.iloc[i][target_col] == 1:\n",
    "                results_per_ps[key][\"has_target\"] = 1\n",
    "\n",
    "    # Compute P(any onset) = 1 - prod(1 - p_d)\n",
    "    y_true_list = []\n",
    "    y_proba_list = []\n",
    "\n",
    "    for key, info in results_per_ps.items():\n",
    "        if not info[\"any_eligible\"]:\n",
    "            continue\n",
    "        probs = info[\"probs\"]\n",
    "        p_no_onset = 1.0\n",
    "        for p in probs:\n",
    "            p_no_onset *= (1 - p)\n",
    "        p_any = 1 - p_no_onset\n",
    "\n",
    "        y_proba_list.append(p_any)\n",
    "        y_true_list.append(info[\"has_target\"])\n",
    "\n",
    "    y_true  = np.array(y_true_list)\n",
    "    y_proba = np.array(y_proba_list)\n",
    "\n",
    "    # Evaluate\n",
    "    roc  = roc_auc_score(y_true, y_proba)\n",
    "    pr   = average_precision_score(y_true, y_proba)\n",
    "    bt, bf2 = find_best_f2_threshold(y_true, y_proba)\n",
    "\n",
    "    print(\"\\n  ANY-ONSET Combined:\")\n",
    "    print(f\"    ROC-AUC:  {roc:.4f}\")\n",
    "    print(f\"    PR-AUC:   {pr:.4f}\")\n",
    "    print(f\"    Best F2:  {bf2:.4f} @ threshold {bt:.3f}\")\n",
    "    print(f\"    Samples:  {len(y_true):,} | Events: {y_true.sum():,.0f} ({y_true.mean():.2%})\")\n",
    "\n",
    "    return {\"roc_auc\": roc, \"pr_auc\": pr, \"f2\": bf2, \"threshold\": bt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 8: EXPLAINABILITY (SHAP)\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def explain_expert(models, X_test, feature_cols, disease, top_n=20):\n",
    "    \"\"\"SHAP summary for the LightGBM expert of this disease.\"\"\"\n",
    "    try:\n",
    "        import shap\n",
    "        import matplotlib\n",
    "        matplotlib.use(\"Agg\")\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        model = models[\"lgb\"]\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1]\n",
    "\n",
    "        # Summary plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_test, max_display=top_n, show=False)\n",
    "        plt.title(f\"SHAP — {disease.upper()} Expert\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / f\"shap_{disease}.png\", dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"  Saved SHAP plot: shap_{disease}.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"  SHAP failed for {disease}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 9: FEATURE IMPORTANCE EXPORT\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def export_importance(all_models, all_feature_cols):\n",
    "    \"\"\"Export feature importance per disease expert.\"\"\"\n",
    "    rows = []\n",
    "    for disease, models in all_models.items():\n",
    "        feat_cols = all_feature_cols[disease]\n",
    "        lgb_imp = models[\"lgb\"].feature_importances_\n",
    "        cat_imp = models[\"cat\"].get_feature_importance()\n",
    "        xgb_imp = models[\"xgb\"].feature_importances_\n",
    "\n",
    "        for i, feat in enumerate(feat_cols):\n",
    "            rows.append({\n",
    "                \"disease\": disease,\n",
    "                \"feature\": feat,\n",
    "                \"lgb\": lgb_imp[i],\n",
    "                \"cat\": cat_imp[i],\n",
    "                \"xgb\": xgb_imp[i],\n",
    "                \"avg\": (lgb_imp[i] + cat_imp[i] + xgb_imp[i]) / 3,\n",
    "            })\n",
    "\n",
    "    df_imp = pd.DataFrame(rows)\n",
    "    df_imp.to_csv(OUTPUT_DIR / \"feature_importance_experts.csv\", index=False)\n",
    "    print(f\"\\n  Saved feature_importance_experts.csv ({len(df_imp)} rows)\")\n",
    "\n",
    "    # Print top-10 per disease\n",
    "    for disease in DISEASE_MAP:\n",
    "        sub = df_imp[df_imp[\"disease\"] == disease].nlargest(10, \"avg\")\n",
    "        print(f\"\\n  TOP-10 {disease.upper()}:\")\n",
    "        for _, row in sub.iterrows():\n",
    "            print(f\"    {row['feature']:<30} avg={row['avg']:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  PHASE 10: FAIRNESS AUDIT\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "def fairness_audit(disease, y_test, y_proba, threshold, demo_test):\n",
    "    \"\"\"Quick fairness check across demographics.\"\"\"\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n  Fairness — {disease.upper()}\")\n",
    "\n",
    "    # Gender\n",
    "    for gval, gname in {0: \"Male\", 1: \"Female\"}.items():\n",
    "        mask = demo_test[\"female\"].values == gval\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        g_rec = recall_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_prec = precision_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_f2  = fbeta_score(y_test.values[mask], y_pred[mask], beta=2, zero_division=0)\n",
    "        print(f\"    {gname:<12}: F2={g_f2:.4f}  P={g_prec:.4f}  R={g_rec:.4f} (n={mask.sum():,})\")\n",
    "\n",
    "    # Ethnicity\n",
    "    for eth in [\"White\", \"Black\", \"Hispanic\", \"Other\"]:\n",
    "        mask = demo_test[\"ethnicity\"].values == eth\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        g_rec = recall_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_prec = precision_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_f2  = fbeta_score(y_test.values[mask], y_pred[mask], beta=2, zero_division=0)\n",
    "        print(f\"    {eth:<12}: F2={g_f2:.4f}  P={g_prec:.4f}  R={g_rec:.4f} (n={mask.sum():,})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  HYBRID DISEASE-EXPERT ENSEMBLE\n",
      "=================================================================\n",
      "  Data:    /teamspace/studios/this_studio/data/extracted/randhrs1992_2022v1.parquet\n",
      "  Output:  /teamspace/studios/this_studio/output_hybrid\n",
      "  Horizon: 2 screenings (~4 years)\n",
      "  Diseases: ['diabetes', 'cvd', 'stroke', 'lung', 'cancer', 'hibp', 'arthritis', 'psychiatric', 'memory']\n",
      "\n",
      "  Loading parquet data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (45234, 19880)\n",
      "\n",
      "=================================================================\n",
      "  PHASE 1-3: BUILDING FEATURES + TARGETS\n",
      "=================================================================\n",
      "  Screening 5 → 7: 45,234 rows, 150 features\n",
      "  Screening 6 → 8: 45,234 rows, 150 features\n",
      "  Screening 7 → 9: 45,234 rows, 150 features\n",
      "  Screening 8 → 10: 45,234 rows, 150 features\n",
      "  Screening 9 → 11: 45,234 rows, 150 features\n",
      "  Screening 10 → 12: 45,234 rows, 150 features\n",
      "  Screening 11 → 13: 45,234 rows, 150 features\n",
      "  Screening 12 → 14: 45,234 rows, 150 features\n",
      "\n",
      "  TOTAL: 361,872 rows\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): DIABETES\n",
      "=================================================================\n",
      "  Train: 76,088 | Pos: 5,381 (7.07%) | scale_pos_weight: 13.1\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.6705\n",
      "  CatBoost  ROC-AUC: 0.7030\n",
      "  XGBoost   ROC-AUC: 0.7009\n",
      "  Ensemble  ROC-AUC: 0.7030\n",
      "  diabetes/lgb: ROC=0.6705 PR=0.1204 F2=0.3254 P=0.1026 R=0.7118 t=0.087\n",
      "  diabetes/cat: ROC=0.7030 PR=0.1426 F2=0.3556 P=0.1196 R=0.7013 t=0.481\n",
      "  diabetes/xgb: ROC=0.7009 PR=0.1405 F2=0.3512 P=0.1191 R=0.6849 t=0.475\n",
      "  diabetes/avg: ROC=0.7030 PR=0.1420 F2=0.3561 P=0.1200 R=0.7006 t=0.346\n",
      "\n",
      "  Fairness — DIABETES\n",
      "    Male        : F2=0.3550  P=0.1169  R=0.7236 (n=7,670)\n",
      "    Female      : F2=0.3569  P=0.1226  R=0.6836 (n=11,537)\n",
      "    White       : F2=0.3197  P=0.1089  R=0.6195 (n=14,355)\n",
      "    Black       : F2=0.3790  P=0.1206  R=0.8164 (n=2,604)\n",
      "    Hispanic    : F2=0.4325  P=0.1469  R=0.8411 (n=1,789)\n",
      "    Other       : F2=0.5023  P=0.1982  R=0.8148 (n=459)\n",
      "  Saved SHAP plot: shap_diabetes.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): CVD\n",
      "=================================================================\n",
      "  Train: 73,925 | Pos: 6,748 (9.13%) | scale_pos_weight: 10.0\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.6631\n",
      "  CatBoost  ROC-AUC: 0.6792\n",
      "  XGBoost   ROC-AUC: 0.6815\n",
      "  Ensemble  ROC-AUC: 0.6822\n",
      "  cvd/lgb: ROC=0.6631 PR=0.1610 F2=0.3859 P=0.1400 R=0.6879 t=0.107\n",
      "  cvd/cat: ROC=0.6792 PR=0.1782 F2=0.3995 P=0.1411 R=0.7371 t=0.422\n",
      "  cvd/xgb: ROC=0.6815 PR=0.1771 F2=0.3969 P=0.1378 R=0.7486 t=0.402\n",
      "  cvd/avg: ROC=0.6822 PR=0.1798 F2=0.3992 P=0.1365 R=0.7698 t=0.300\n",
      "\n",
      "  Fairness — CVD\n",
      "    Male        : F2=0.4197  P=0.1443  R=0.8025 (n=6,887)\n",
      "    Female      : F2=0.3849  P=0.1310  R=0.7466 (n=11,682)\n",
      "    White       : F2=0.4171  P=0.1428  R=0.8024 (n=12,884)\n",
      "    Black       : F2=0.3387  P=0.1115  R=0.6907 (n=2,988)\n",
      "    Hispanic    : F2=0.3500  P=0.1236  R=0.6456 (n=2,229)\n",
      "    Other       : F2=0.3698  P=0.1377  R=0.6389 (n=468)\n",
      "  Saved SHAP plot: shap_cvd.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): STROKE\n",
      "=================================================================\n",
      "  Train: 89,527 | Pos: 2,785 (3.11%) | scale_pos_weight: 31.1\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.6561\n",
      "  CatBoost  ROC-AUC: 0.6796\n",
      "  XGBoost   ROC-AUC: 0.6827\n",
      "  Ensemble  ROC-AUC: 0.6835\n",
      "  stroke/lgb: ROC=0.6561 PR=0.0543 F2=0.1956 P=0.0530 R=0.5965 t=0.043\n",
      "  stroke/cat: ROC=0.6796 PR=0.0626 F2=0.1960 P=0.0551 R=0.5424 t=0.466\n",
      "  stroke/xgb: ROC=0.6827 PR=0.0631 F2=0.1971 P=0.0562 R=0.5278 t=0.478\n",
      "  stroke/avg: ROC=0.6835 PR=0.0641 F2=0.1999 P=0.0560 R=0.5585 t=0.323\n",
      "\n",
      "  Fairness — STROKE\n",
      "    Male        : F2=0.1924  P=0.0536  R=0.5460 (n=9,490)\n",
      "    Female      : F2=0.2064  P=0.0581  R=0.5691 (n=12,800)\n",
      "    White       : F2=0.2053  P=0.0582  R=0.5567 (n=15,656)\n",
      "    Black       : F2=0.2024  P=0.0554  R=0.6000 (n=3,562)\n",
      "    Hispanic    : F2=0.1488  P=0.0399  R=0.4667 (n=2,540)\n",
      "    Other       : F2=0.2518  P=0.0707  R=0.7000 (n=532)\n",
      "  Saved SHAP plot: shap_stroke.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): LUNG\n",
      "=================================================================\n",
      "  Train: 86,700 | Pos: 3,225 (3.72%) | scale_pos_weight: 25.9\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.7052\n",
      "  CatBoost  ROC-AUC: 0.7330\n",
      "  XGBoost   ROC-AUC: 0.7306\n",
      "  Ensemble  ROC-AUC: 0.7345\n",
      "  lung/lgb: ROC=0.7052 PR=0.0813 F2=0.2385 P=0.0677 R=0.6460 t=0.049\n",
      "  lung/cat: ROC=0.7330 PR=0.1016 F2=0.2618 P=0.0876 R=0.5209 t=0.556\n",
      "  lung/xgb: ROC=0.7306 PR=0.1035 F2=0.2587 P=0.0970 R=0.4437 t=0.536\n",
      "  lung/avg: ROC=0.7345 PR=0.1063 F2=0.2680 P=0.1048 R=0.4387 t=0.399\n",
      "\n",
      "  Fairness — LUNG\n",
      "    Male        : F2=0.2583  P=0.0985  R=0.4343 (n=8,611)\n",
      "    Female      : F2=0.2740  P=0.1089  R=0.4413 (n=12,954)\n",
      "    White       : F2=0.2878  P=0.1130  R=0.4693 (n=15,191)\n",
      "    Black       : F2=0.2415  P=0.0888  R=0.4237 (n=3,502)\n",
      "    Hispanic    : F2=0.1224  P=0.0472  R=0.2034 (n=2,359)\n",
      "    Other       : F2=0.2890  P=0.1639  R=0.3571 (n=513)\n",
      "  Saved SHAP plot: shap_lung.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): CANCER\n",
      "=================================================================\n",
      "  Train: 83,170 | Pos: 4,154 (4.99%) | scale_pos_weight: 19.0\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.5662\n",
      "  CatBoost  ROC-AUC: 0.6014\n",
      "  XGBoost   ROC-AUC: 0.5936\n",
      "  Ensemble  ROC-AUC: 0.5982\n",
      "  cancer/lgb: ROC=0.5662 PR=0.0638 F2=0.2182 P=0.0578 R=0.7128 t=0.058\n",
      "  cancer/cat: ROC=0.6014 PR=0.0734 F2=0.2382 P=0.0662 R=0.6794 t=0.460\n",
      "  cancer/xgb: ROC=0.5936 PR=0.0711 F2=0.2340 P=0.0629 R=0.7314 t=0.422\n",
      "  cancer/avg: ROC=0.5982 PR=0.0723 F2=0.2355 P=0.0641 R=0.7119 t=0.311\n",
      "\n",
      "  Fairness — CANCER\n",
      "    Male        : F2=0.2746  P=0.0737  R=0.8615 (n=8,638)\n",
      "    Female      : F2=0.1951  P=0.0538  R=0.5683 (n=12,314)\n",
      "    White       : F2=0.2441  P=0.0656  R=0.7638 (n=14,606)\n",
      "    Black       : F2=0.2160  P=0.0602  R=0.6122 (n=3,387)\n",
      "    Hispanic    : F2=0.1665  P=0.0493  R=0.4110 (n=2,321)\n",
      "    Other       : F2=0.1965  P=0.0638  R=0.4091 (n=638)\n",
      "  Saved SHAP plot: shap_cancer.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): HIBP\n",
      "=================================================================\n",
      "  Train: 41,274 | Pos: 8,184 (19.83%) | scale_pos_weight: 4.0\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.6000\n",
      "  CatBoost  ROC-AUC: 0.6170\n",
      "  XGBoost   ROC-AUC: 0.6189\n",
      "  Ensemble  ROC-AUC: 0.6194\n",
      "  hibp/lgb: ROC=0.6000 PR=0.2504 F2=0.5625 P=0.2162 R=0.9383 t=0.209\n",
      "  hibp/cat: ROC=0.6170 PR=0.2678 F2=0.5637 P=0.2113 R=0.9672 t=0.297\n",
      "  hibp/xgb: ROC=0.6189 PR=0.2721 F2=0.5634 P=0.2190 R=0.9285 t=0.346\n",
      "  hibp/avg: ROC=0.6194 PR=0.2717 F2=0.5654 P=0.2143 R=0.9579 t=0.282\n",
      "\n",
      "  Fairness — HIBP\n",
      "    Male        : F2=0.5748  P=0.2184  R=0.9708 (n=4,265)\n",
      "    Female      : F2=0.5581  P=0.2110  R=0.9478 (n=6,056)\n",
      "    White       : F2=0.5439  P=0.2010  R=0.9484 (n=7,818)\n",
      "    Black       : F2=0.6420  P=0.2650  R=0.9964 (n=1,078)\n",
      "    Hispanic    : F2=0.6084  P=0.2424  R=0.9771 (n=1,134)\n",
      "    Other       : F2=0.5906  P=0.2419  R=0.9231 (n=291)\n",
      "  Saved SHAP plot: shap_hibp.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): ARTHRITIS\n",
      "=================================================================\n",
      "  Train: 39,069 | Pos: 7,932 (20.30%) | scale_pos_weight: 3.9\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.6397\n",
      "  CatBoost  ROC-AUC: 0.6473\n",
      "  XGBoost   ROC-AUC: 0.6424\n",
      "  Ensemble  ROC-AUC: 0.6480\n",
      "  arthritis/lgb: ROC=0.6397 PR=0.3007 F2=0.5603 P=0.2119 R=0.9516 t=0.215\n",
      "  arthritis/cat: ROC=0.6473 PR=0.3080 F2=0.5648 P=0.2288 R=0.8923 t=0.376\n",
      "  arthritis/xgb: ROC=0.6424 PR=0.3099 F2=0.5619 P=0.2072 R=0.9822 t=0.233\n",
      "  arthritis/avg: ROC=0.6480 PR=0.3130 F2=0.5625 P=0.2077 R=0.9817 t=0.250\n",
      "\n",
      "  Fairness — ARTHRITIS\n",
      "    Male        : F2=0.5165  P=0.1790  R=0.9771 (n=4,825)\n",
      "    Female      : F2=0.5992  P=0.2335  R=0.9849 (n=5,215)\n",
      "    White       : F2=0.5620  P=0.2066  R=0.9865 (n=6,952)\n",
      "    Black       : F2=0.5905  P=0.2284  R=0.9781 (n=1,431)\n",
      "    Hispanic    : F2=0.5503  P=0.2018  R=0.9680 (n=1,311)\n",
      "    Other       : F2=0.4813  P=0.1628  R=0.9423 (n=346)\n",
      "  Saved SHAP plot: shap_arthritis.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): PSYCHIATRIC\n",
      "=================================================================\n",
      "  Train: 78,618 | Pos: 3,938 (5.01%) | scale_pos_weight: 19.0\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.6798\n",
      "  CatBoost  ROC-AUC: 0.7257\n",
      "  XGBoost   ROC-AUC: 0.7300\n",
      "  Ensemble  ROC-AUC: 0.7309\n",
      "  psychiatric/lgb: ROC=0.6798 PR=0.0989 F2=0.2612 P=0.0920 R=0.4837 t=0.061\n",
      "  psychiatric/cat: ROC=0.7257 PR=0.1251 F2=0.3065 P=0.1136 R=0.5325 t=0.545\n",
      "  psychiatric/xgb: ROC=0.7300 PR=0.1274 F2=0.3060 P=0.1018 R=0.6139 t=0.463\n",
      "  psychiatric/avg: ROC=0.7309 PR=0.1283 F2=0.3044 P=0.1096 R=0.5477 t=0.361\n",
      "\n",
      "  Fairness — PSYCHIATRIC\n",
      "    Male        : F2=0.2440  P=0.0947  R=0.4026 (n=8,941)\n",
      "    Female      : F2=0.3311  P=0.1155  R=0.6205 (n=10,717)\n",
      "    White       : F2=0.3194  P=0.1201  R=0.5459 (n=13,663)\n",
      "    Black       : F2=0.2749  P=0.0867  R=0.6016 (n=3,289)\n",
      "    Hispanic    : F2=0.2901  P=0.0988  R=0.5625 (n=2,184)\n",
      "    Other       : F2=0.1869  P=0.0784  R=0.2857 (n=522)\n",
      "  Saved SHAP plot: shap_psychiatric.png\n",
      "\n",
      "=================================================================\n",
      "  EXPERT (Leakage-Safe): MEMORY\n",
      "=================================================================\n",
      "  Train: 35,753 | Pos: 989 (2.77%) | scale_pos_weight: 35.2\n",
      "  Categorical features: ['ethnicity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM  ROC-AUC: 0.7850\n",
      "  CatBoost  ROC-AUC: 0.8281\n",
      "  XGBoost   ROC-AUC: 0.8314\n",
      "  Ensemble  ROC-AUC: 0.8332\n",
      "  memory/lgb: ROC=0.7850 PR=0.1339 F2=0.3184 P=0.1470 R=0.4494 t=0.064\n",
      "  memory/cat: ROC=0.8281 PR=0.1523 F2=0.3321 P=0.1136 R=0.6397 t=0.600\n",
      "  memory/xgb: ROC=0.8314 PR=0.1769 F2=0.3490 P=0.1405 R=0.5547 t=0.594\n",
      "  memory/avg: ROC=0.8332 PR=0.1676 F2=0.3612 P=0.1546 R=0.5425 t=0.454\n",
      "\n",
      "  Fairness — MEMORY\n",
      "    Male        : F2=0.3160  P=0.1339  R=0.4787 (n=3,702)\n",
      "    Female      : F2=0.3893  P=0.1676  R=0.5817 (n=5,100)\n",
      "    White       : F2=0.3392  P=0.1483  R=0.5000 (n=6,854)\n",
      "    Black       : F2=0.4748  P=0.1939  R=0.7442 (n=1,168)\n",
      "    Hispanic    : F2=0.3125  P=0.1310  R=0.4783 (n=628)\n",
      "    Other       : F2=0.3333  P=0.1111  R=0.6667 (n=152)\n",
      "  Saved SHAP plot: shap_memory.png\n"
     ]
    }
   ],
   "source": [
    "# ═════════════════════════════════════════════════════════════════════\n",
    "#  MAIN\n",
    "# ═════════════════════════════════════════════════════════════════════\n",
    "\n",
    "banner(\"HYBRID DISEASE-EXPERT ENSEMBLE\")\n",
    "print(f\"  Data:    {DATA_PATH}\")\n",
    "print(f\"  Output:  {OUTPUT_DIR}\")\n",
    "print(f\"  Horizon: {PREDICTION_HORIZON} screenings (~{PREDICTION_HORIZON*2} years)\")\n",
    "print(f\"  Diseases: {list(DISEASE_MAP.keys())}\")\n",
    "\n",
    "# Load raw\n",
    "print(\"\\n  Loading parquet data...\")\n",
    "df_raw = pd.read_parquet(str(DATA_PATH))\n",
    "print(f\"  Shape: {df_raw.shape}\")\n",
    "\n",
    "# Build master feature+target dataset\n",
    "master = build_master_features(df_raw)\n",
    "\n",
    "# Train one expert per disease\n",
    "all_models = {}\n",
    "all_results = {}\n",
    "all_feature_cols = {}\n",
    "\n",
    "for disease in DISEASE_MAP:\n",
    "    try:\n",
    "        feature_cols, X_tr, y_tr, X_te, y_te, demo = get_disease_dataset(master, disease)\n",
    "        all_feature_cols[disease] = feature_cols\n",
    "\n",
    "        models, results, avg_pred = train_disease_expert(\n",
    "            disease, feature_cols, X_tr, y_tr, X_te, y_te\n",
    "        )\n",
    "        all_models[disease] = models\n",
    "        all_results[disease] = results\n",
    "\n",
    "        # Best threshold from ensemble average\n",
    "        bt = results[\"avg\"][\"threshold\"]\n",
    "        fairness_audit(disease, y_te, avg_pred, bt, demo)\n",
    "        explain_expert(models, X_te, feature_cols, disease)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n  ERROR for {disease}: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  META-ENSEMBLE: ANY-DISEASE ONSET\n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ANY-ONSET Combined:\n",
      "    ROC-AUC:  0.6565\n",
      "    PR-AUC:   0.4990\n",
      "    Best F2:  0.7318 @ threshold 0.600\n",
      "    Samples:  119,986 | Events: 42,228 (35.19%)\n",
      "\n",
      "  Saved feature_importance_experts.csv (1341 rows)\n",
      "\n",
      "  TOP-10 DIABETES:\n",
      "    bmi                            avg=8.0\n",
      "    age                            avg=4.5\n",
      "    condition_count                avg=2.9\n",
      "    weight                         avg=2.3\n",
      "    weight_lag2                    avg=2.2\n",
      "    memory_recall                  avg=2.1\n",
      "    birth_year                     avg=2.0\n",
      "    drinks_per_week                avg=2.0\n",
      "    ethnicity                      avg=2.0\n",
      "    bmi_lag2                       avg=1.9\n",
      "\n",
      "  TOP-10 CVD:\n",
      "    birth_year                     avg=7.3\n",
      "    condition_count                avg=4.6\n",
      "    self_rated_health_lag1         avg=3.6\n",
      "    weight_lag2                    avg=2.1\n",
      "    self_rated_health              avg=2.1\n",
      "    out_of_pocket_lag1             avg=1.9\n",
      "    height_lag2                    avg=1.8\n",
      "    age                            avg=1.8\n",
      "    out_of_pocket_lag2             avg=1.8\n",
      "    bmi_lag2                       avg=1.7\n",
      "\n",
      "  TOP-10 STROKE:\n",
      "    self_rated_health              avg=2.2\n",
      "    memory_recall                  avg=2.1\n",
      "    birth_year                     avg=2.1\n",
      "    age                            avg=1.7\n",
      "    out_of_pocket_lag1             avg=1.6\n",
      "    condition_count                avg=1.5\n",
      "    weight                         avg=1.4\n",
      "    age_squared                    avg=1.2\n",
      "    weight_change_kg               avg=1.2\n",
      "    condition_count_lag1           avg=1.1\n",
      "\n",
      "  TOP-10 LUNG:\n",
      "    self_rated_health              avg=2.6\n",
      "    condition_count                avg=2.4\n",
      "    birth_year                     avg=2.4\n",
      "    ever_smoked                    avg=2.4\n",
      "    bmi_x_smoking                  avg=1.6\n",
      "    bmi_accel                      avg=1.6\n",
      "    bmi_lag1                       avg=1.4\n",
      "    bmi                            avg=1.4\n",
      "    any_mobility                   avg=1.3\n",
      "    age                            avg=1.3\n",
      "\n",
      "  TOP-10 CANCER:\n",
      "    age                            avg=3.1\n",
      "    birth_year                     avg=2.9\n",
      "    female                         avg=2.1\n",
      "    age_squared                    avg=1.9\n",
      "    age_x_cesd                     avg=1.8\n",
      "    education                      avg=1.6\n",
      "    height                         avg=1.4\n",
      "    self_rated_health              avg=1.4\n",
      "    cog_decline_x_age              avg=1.3\n",
      "    condition_count                avg=1.3\n",
      "\n",
      "  TOP-10 HIBP:\n",
      "    age_x_bmi                      avg=6.8\n",
      "    birth_year                     avg=6.6\n",
      "    cognition                      avg=4.5\n",
      "    bmi                            avg=4.2\n",
      "    bmi_x_smoking                  avg=3.5\n",
      "    bmi_lag2                       avg=3.2\n",
      "    screening_year                 avg=3.2\n",
      "    weight_lag1                    avg=3.1\n",
      "    marital_status                 avg=2.8\n",
      "    self_rated_health              avg=2.8\n",
      "\n",
      "  TOP-10 ARTHRITIS:\n",
      "    birth_year                     avg=7.2\n",
      "    large_muscle                   avg=6.7\n",
      "    age_x_bmi                      avg=5.3\n",
      "    out_of_pocket                  avg=4.8\n",
      "    condition_count                avg=4.7\n",
      "    female                         avg=4.6\n",
      "    age_x_cesd                     avg=4.3\n",
      "    bmi                            avg=4.2\n",
      "    screening_year                 avg=4.2\n",
      "    out_of_pocket_lag2             avg=3.9\n",
      "\n",
      "  TOP-10 PSYCHIATRIC:\n",
      "    age_x_cesd                     avg=3.3\n",
      "    self_rated_health              avg=2.2\n",
      "    weight_change_kg               avg=1.8\n",
      "    cesd_lag2                      avg=1.8\n",
      "    cognition                      avg=1.6\n",
      "    female                         avg=1.6\n",
      "    age                            avg=1.5\n",
      "    bmi_delta_lag1                 avg=1.4\n",
      "    weight                         avg=1.4\n",
      "    condition_count                avg=1.2\n",
      "\n",
      "  TOP-10 MEMORY:\n",
      "    age                            avg=4.4\n",
      "    delayed_recall                 avg=3.6\n",
      "    out_of_pocket                  avg=2.9\n",
      "    memory_recall                  avg=2.9\n",
      "    cognition                      avg=2.7\n",
      "    age_squared                    avg=2.4\n",
      "    weight                         avg=1.9\n",
      "    working                        avg=1.9\n",
      "    bmi                            avg=1.9\n",
      "    weight_lag2                    avg=1.8\n",
      "\n",
      "  Saved results.json\n",
      "\n",
      "=================================================================\n",
      "  FINAL SUMMARY\n",
      "=================================================================\n",
      "Disease         ROC-AUC   PR-AUC       F2   Recall     Prec\n",
      "--------------------------------------------------------------\n",
      "diabetes         0.7030   0.1420   0.3561   0.7006   0.1200\n",
      "cvd              0.6822   0.1798   0.3992   0.7698   0.1365\n",
      "stroke           0.6835   0.0641   0.1999   0.5585   0.0560\n",
      "lung             0.7345   0.1063   0.2680   0.4387   0.1048\n",
      "cancer           0.5982   0.0723   0.2355   0.7119   0.0641\n",
      "hibp             0.6194   0.2717   0.5654   0.9579   0.2143\n",
      "arthritis        0.6480   0.3130   0.5625   0.9817   0.2077\n",
      "psychiatric      0.7309   0.1283   0.3044   0.5477   0.1096\n",
      "memory           0.8332   0.1676   0.3612   0.5425   0.1546\n",
      "ANY-ONSET        0.6565   0.4990   0.7318\n"
     ]
    }
   ],
   "source": [
    "# Meta-ensemble: any-onset\n",
    "if all_models:\n",
    "    any_onset_results = build_any_onset_from_experts(\n",
    "        master, all_models, all_feature_cols\n",
    "    )\n",
    "    all_results[\"_any_onset_combined\"] = any_onset_results\n",
    "\n",
    "# Export\n",
    "if all_models:\n",
    "    export_importance(all_models, all_feature_cols)\n",
    "\n",
    "# Save results\n",
    "with open(OUTPUT_DIR / \"results.json\", \"w\") as f:\n",
    "    json.dump(all_results, f, indent=2, default=str)\n",
    "print(\"\\n  Saved results.json\")\n",
    "\n",
    "# ── FINAL SUMMARY ──\n",
    "banner(\"FINAL SUMMARY\")\n",
    "print(f\"{'Disease':<14} {'ROC-AUC':>8} {'PR-AUC':>8} {'F2':>8} {'Recall':>8} {'Prec':>8}\")\n",
    "print(\"-\" * 62)\n",
    "for disease, res in all_results.items():\n",
    "    if disease.startswith(\"_\"):\n",
    "        # Meta-ensemble\n",
    "        r = res\n",
    "        print(f\"{'ANY-ONSET':<14} {r.get('roc_auc',0):>8.4f} {r.get('pr_auc',0):>8.4f} \"\n",
    "                f\"{r.get('f2',0):>8.4f}\")\n",
    "    else:\n",
    "        r = res.get(\"avg\", {})\n",
    "        print(f\"{disease:<14} {r.get('roc_auc',0):>8.4f} {r.get('pr_auc',0):>8.4f} \"\n",
    "                f\"{r.get('f2',0):>8.4f} {r.get('recall',0):>8.4f} {r.get('precision',0):>8.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
