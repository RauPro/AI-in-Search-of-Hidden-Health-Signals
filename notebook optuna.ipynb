{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import traceback\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    fbeta_score, roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH  = Path.cwd() / \"data\" / \"extracted\" / \"randhrs1992_2022v1.parquet\"\n",
    "OUTPUT_DIR = Path.cwd() / \"output_hybrid\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Screenings where we measure features \u2192 outcome is screening + HORIZON\n",
    "FEATURE_SCREENINGS = list(range(5, 13))   # HRS screenings 5..12\n",
    "PREDICTION_HORIZON = 2                    # 2 screenings ahead (~4 years)\n",
    "LAGS = 2                                  # use current, prev, prev-prev screening\n",
    "\n",
    "# 8 disease experts \u2014 screening-specific self-report codes (NOT cumulative \"E\" vars)\n",
    "DISEASE_MAP = {\n",
    "    \"diabetes\":    \"DIAB\",\n",
    "    \"cvd\":         \"HEART\",\n",
    "    \"stroke\":      \"STROK\",\n",
    "    \"lung\":        \"LUNG\",\n",
    "    \"cancer\":      \"CANCR\",\n",
    "    \"hibp\":        \"HIBP\",\n",
    "    \"arthritis\":   \"ARTHR\",\n",
    "    \"psychiatric\": \"PSYCH\",\n",
    "    \"memory\":      \"MEMRY\",\n",
    "}\n",
    "\n",
    "SCREENING_VARS = {\n",
    "    \"self_rated_health\": \"SHLT\",\n",
    "    \"bmi\":               \"BMI\",\n",
    "    \"weight\":            \"WEIGHT\",\n",
    "    \"height\":            \"HEIGHT\",\n",
    "    \"mobility\":          \"MOBILA\",\n",
    "    \"gross_motor\":       \"GROSSA\",\n",
    "    \"large_muscle\":      \"LGMUSA\",\n",
    "    \"fine_motor\":        \"FINEA\",\n",
    "    \"adl\":               \"ADL5A\",\n",
    "    \"iadl\":              \"IADL5A\",\n",
    "    \"cognition\":         \"COG27\",\n",
    "    \"memory_recall\":     \"TR20\",\n",
    "    \"immediate_recall\":  \"IMRC\", # ImputedCognition:ImmediateWordRecall #missing\n",
    "    \"delayed_recall\":    \"DLRC\", # DelayedWordRecall #missing\n",
    "    \"serial7\":           \"SER7\",\n",
    "    \"cesd\":              \"CESD\",\n",
    "    \"depressed\":         \"DEPRES\",\n",
    "    \"effort\":            \"EFFORT\",\n",
    "    \"restless_sleep\":    \"SLEEPR\",\n",
    "    \"lonely\":            \"FLONE\",\n",
    "    \"ever_smoked\":       \"SMOKEV\",\n",
    "    \"current_smoker\":    \"SMOKEN\",\n",
    "    \"drinks_per_day\":    \"DRINKD\",\n",
    "    \"drink_days_week\":   \"DRINKN\",\n",
    "    \"vigorous_activity\": \"VGACTX\",\n",
    "    \"marital_status\":    \"MSTAT\", # missing\n",
    "    \"condition_count\":   \"CONDE\", # CONDE that is the sum of indicators for whether a doctor has ever told the Respondent thats/he has ever had a particular disease. missing\n",
    "    \"self_health_comp\":  \"SHLTC\",\n",
    "    \"out_of_pocket\":     \"OOPMD\", # out-of-pocket spending\n",
    "    \"working\":           \"WORK\",\n",
    "}\n",
    "\n",
    "# HRS screening \u2192 approximate year (fallback when interview date missing)\n",
    "SCREENING_YEARS = {\n",
    "    1:1992, 2:1993, 3:1994, 4:1995, 5:1996, 6:1998, 7:2000,\n",
    "    8:2002, 9:2004, 10:2006, 11:2008, 12:2010, 13:2012,\n",
    "    14:2014, 15:2016, 16:2018, 17:2020, 18:2022\n",
    "}\n",
    "\n",
    "def banner(msg):\n",
    "    print(f\"\\n{'='*65}\\n  {msg}\\n{'='*65}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_screening_features(df_raw: pd.DataFrame, scr: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a given screening, extract:\n",
    "      - Demographics (static)\n",
    "      - Current screening values\n",
    "      - Lag-1 and Lag-2 values (raw)\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    # Person identifier\n",
    "    data[\"person_id\"] = df_raw[\"HHIDPN\"].values\n",
    "\n",
    "    # Screening date (interview midpoint: SAS date = days since 1960-01-01)\n",
    "    SAS_EPOCH = pd.Timestamp(\"1960-01-01\")\n",
    "    iw_col = f\"R{scr}IWMID\"\n",
    "    if iw_col in df_raw.columns:\n",
    "        iw_days = pd.to_numeric(df_raw[iw_col], errors=\"coerce\")\n",
    "        screening_date = SAS_EPOCH + pd.to_timedelta(iw_days, unit=\"D\")\n",
    "        data[\"screening_year\"]  = screening_date.dt.year.values.astype(float)\n",
    "        data[\"screening_month\"] = screening_date.dt.month.values.astype(float)\n",
    "    else:\n",
    "        data[\"screening_year\"]  = float(SCREENING_YEARS[scr])\n",
    "        data[\"screening_month\"] = np.nan\n",
    "\n",
    "    # Time gap to previous screening (in years)\n",
    "    iw_lag1_col = f\"R{scr - 1}IWMID\" if scr > 1 else None\n",
    "    if iw_lag1_col and iw_lag1_col in df_raw.columns and iw_col in df_raw.columns:\n",
    "        iw_cur  = pd.to_numeric(df_raw[iw_col], errors=\"coerce\")\n",
    "        iw_prev = pd.to_numeric(df_raw[iw_lag1_col], errors=\"coerce\")\n",
    "        data[\"years_since_last_screening\"] = ((iw_cur - iw_prev) / 365.25).values\n",
    "    else:\n",
    "        data[\"years_since_last_screening\"] = np.nan\n",
    "\n",
    "    # Static demographics \u2014 age from actual screening date\n",
    "    birth_year = pd.to_numeric(df_raw[\"RABYEAR\"], errors=\"coerce\")\n",
    "    age = data[\"screening_year\"] - birth_year.values\n",
    "    data[\"birth_year\"] = birth_year.values\n",
    "    data[\"age\"] = age\n",
    "    data[\"age_squared\"] = age ** 2\n",
    "\n",
    "    data[\"female\"]    = (pd.to_numeric(df_raw[\"RAGENDER\"], errors=\"coerce\") == 2).astype(int).values\n",
    "\n",
    "    race = pd.to_numeric(df_raw[\"RARACEM\"], errors=\"coerce\")\n",
    "    hisp = pd.to_numeric(df_raw[\"RAHISPAN\"], errors=\"coerce\")\n",
    "    def map_ethnicity(r, h):\n",
    "        if h == 1:\n",
    "            return \"Hispanic\"\n",
    "        if r == 1:\n",
    "            return \"White\"\n",
    "        if r == 2:\n",
    "            return \"Black\"\n",
    "        return \"Other\"\n",
    "    \n",
    "    data[\"ethnicity\"] = pd.Categorical(\n",
    "        [map_ethnicity(r, h) for r, h in zip(race, hisp)],\n",
    "        categories=[\"White\", \"Black\", \"Hispanic\", \"Other\"]\n",
    "    )\n",
    "    \n",
    "    data[\"education\"] = pd.to_numeric(df_raw.get(\"RAEDYRS\"), errors=\"coerce\").values\n",
    "    data[\"edu_cat\"]   = pd.to_numeric(df_raw.get(\"RAEDUC\"), errors=\"coerce\").values\n",
    "    data[\"degree\"]    = pd.to_numeric(df_raw.get(\"RAEDEGRM\"), errors=\"coerce\").values\n",
    "\n",
    "    # Screening / lag extraction\n",
    "    for lag in range(LAGS + 1):\n",
    "        w = scr - lag\n",
    "        if w < 1:\n",
    "            continue\n",
    "        suffix = f\"_lag{lag}\" if lag > 0 else \"\"\n",
    "        for name, code in SCREENING_VARS.items():\n",
    "            col = f\"R{w}{code}\"\n",
    "            if col in df_raw.columns:\n",
    "                data[f\"{name}{suffix}\"] = pd.to_numeric(df_raw[col], errors=\"coerce\").values\n",
    "            else:\n",
    "                data[f\"{name}{suffix}\"] = np.nan\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add velocity, acceleration, decline, and interaction features.\"\"\"\n",
    "    new = {}\n",
    "\n",
    "    new[\"bmi_delta_lag1\"]    = df.get(\"bmi\", np.nan) - df.get(\"bmi_lag1\", np.nan)\n",
    "    new[\"bmi_delta_lag2\"]    = df.get(\"bmi\", np.nan) - df.get(\"bmi_lag2\", np.nan)\n",
    "    new[\"bmi_accel\"]         = new[\"bmi_delta_lag1\"] - (\n",
    "        df.get(\"bmi_lag1\", np.nan) - df.get(\"bmi_lag2\", np.nan)\n",
    "    )\n",
    "    new[\"weight_change_kg\"]  = df.get(\"weight\", np.nan) - df.get(\"weight_lag1\", np.nan)\n",
    "    wl1 = df.get(\"weight_lag1\", np.nan)\n",
    "    new[\"weight_change_pct\"] = np.where(wl1 != 0, new[\"weight_change_kg\"] / wl1 * 100, np.nan)\n",
    "    new[\"obese\"]             = (df.get(\"bmi\", 0) >= 30).astype(int)\n",
    "    new[\"overweight\"]        = ((df.get(\"bmi\", 0) >= 25) & (df.get(\"bmi\", 0) < 30)).astype(int)\n",
    "    new[\"rapid_weight_gain\"] = (new[\"bmi_delta_lag1\"] > 1).astype(int)\n",
    "    new[\"rapid_weight_loss\"] = (new[\"bmi_delta_lag1\"] < -1).astype(int)\n",
    "\n",
    "    new[\"health_decline_lag1\"] = df.get(\"self_rated_health\", np.nan) - df.get(\"self_rated_health_lag1\", np.nan)\n",
    "    new[\"health_decline_lag2\"] = df.get(\"self_rated_health\", np.nan) - df.get(\"self_rated_health_lag2\", np.nan)\n",
    "    new[\"health_worsening\"]    = (new[\"health_decline_lag1\"] > 0).astype(int)\n",
    "    new[\"health_crash\"]        = (new[\"health_decline_lag1\"] >= 2).astype(int)\n",
    "\n",
    "    for base in [\"mobility\", \"adl\", \"iadl\"]:\n",
    "        cur = df.get(base, np.nan)\n",
    "        lag1 = df.get(f\"{base}_lag1\", np.nan)\n",
    "        new[f\"{base}_decline_lag1\"] = cur - lag1\n",
    "        new[f\"{base}_worsening\"]    = (new[f\"{base}_decline_lag1\"] > 0).astype(int)\n",
    "        new[f\"new_{base}_problem\"]  = ((cur > 0) & (lag1 == 0)).astype(int)\n",
    "        new[f\"any_{base}\"]          = (cur > 0).astype(int)\n",
    "\n",
    "    cog    = df.get(\"cognition\", np.nan)\n",
    "    cog_l1 = df.get(\"cognition_lag1\", np.nan)\n",
    "    cog_l2 = df.get(\"cognition_lag2\", np.nan)\n",
    "    new[\"cog_decline_lag1\"]    = cog_l1 - cog\n",
    "    new[\"cog_decline_lag2\"]    = cog_l2 - cog\n",
    "    new[\"cog_worsening\"]       = (new[\"cog_decline_lag1\"] > 0).astype(int)\n",
    "    new[\"sharp_cog_drop\"]      = (new[\"cog_decline_lag1\"] > 3).astype(int)\n",
    "    new[\"low_cognition\"]       = (cog < 12).astype(int)\n",
    "\n",
    "    mem    = df.get(\"memory_recall\", np.nan)\n",
    "    mem_l1 = df.get(\"memory_recall_lag1\", np.nan)\n",
    "    new[\"memory_decline_lag1\"] = mem_l1 - mem\n",
    "    new[\"memory_worsening\"]    = (new[\"memory_decline_lag1\"] > 0).astype(int)\n",
    "\n",
    "    cesd    = df.get(\"cesd\", np.nan)\n",
    "    cesd_l1 = df.get(\"cesd_lag1\", np.nan)\n",
    "    new[\"cesd_increase\"]        = cesd - cesd_l1\n",
    "    new[\"cesd_worsening\"]       = (new[\"cesd_increase\"] > 0).astype(int)\n",
    "    new[\"elevated_depression\"]  = (cesd >= 3).astype(int)\n",
    "    new[\"high_depression\"]      = (cesd >= 4).astype(int)\n",
    "    new[\"chronic_depression\"]   = ((cesd >= 3) & (cesd_l1 >= 3)).astype(int)\n",
    "\n",
    "    new[\"former_smoker\"]  = ((df.get(\"ever_smoked\", 0) == 1) & (df.get(\"current_smoker\", 0) == 0)).astype(int)\n",
    "    new[\"quit_smoking\"]   = ((df.get(\"current_smoker\", 0) == 0) & (df.get(\"current_smoker_lag1\", 0) == 1)).astype(int)\n",
    "    dpd = df.get(\"drinks_per_day\", np.nan)\n",
    "    dpw = df.get(\"drink_days_week\", np.nan)\n",
    "    new[\"drinks_per_week\"]  = dpd * dpw\n",
    "    new[\"heavy_drinking\"]   = (new[\"drinks_per_week\"] > 14).astype(int)\n",
    "\n",
    "    new[\"age_x_bmi\"]             = df.get(\"age\", np.nan) * df.get(\"bmi\", np.nan)\n",
    "    new[\"age_x_cesd\"]            = df.get(\"age\", np.nan) * cesd\n",
    "    new[\"depression_x_mobility\"] = cesd * df.get(\"mobility\", np.nan)\n",
    "    new[\"cog_decline_x_age\"]     = new[\"cog_decline_lag1\"] * df.get(\"age\", np.nan)\n",
    "    new[\"bmi_x_smoking\"]         = df.get(\"bmi\", np.nan) * df.get(\"current_smoker\", np.nan)\n",
    "\n",
    "    new[\"metabolic_risk\"] = (\n",
    "        new[\"obese\"] * 2\n",
    "        + (df.get(\"age\", 0) >= 65).astype(int)\n",
    "    )\n",
    "    new[\"frailty_score\"] = (\n",
    "        (df.get(\"mobility\", 0) > 0).astype(int)\n",
    "        + (cesd >= 3).astype(int)\n",
    "        + (new[\"weight_change_pct\"] < -5).astype(int)\n",
    "    )\n",
    "\n",
    "    # Single concat to prevent fragmentation\n",
    "    result = pd.concat([df, pd.DataFrame(new, index=df.index)], axis=1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_targets(df_raw: pd.DataFrame, feature_screening: int, outcome_screening: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each disease, create:\n",
    "      - target_{disease}: 1 if onset (0\u21921) between feature and outcome screening\n",
    "      - eligible_{disease}: 1 if disease=0 at feature screening\n",
    "    Uses screening-specific self-report codes (0=no, 1=yes, 3=disputes, 4=don't know).\n",
    "    Values 3/4 and NaN are treated as missing (excluded from eligibility/outcome).\n",
    "    \"\"\"\n",
    "    targets = {\"person_id\": df_raw[\"HHIDPN\"].values}\n",
    "\n",
    "    for disease_name, code in DISEASE_MAP.items():\n",
    "        baseline_col = f\"R{feature_screening}{code}\"\n",
    "        outcome_col  = f\"R{outcome_screening}{code}\"\n",
    "\n",
    "        if baseline_col in df_raw.columns and outcome_col in df_raw.columns:\n",
    "            baseline = pd.to_numeric(df_raw[baseline_col], errors=\"coerce\")\n",
    "            outcome  = pd.to_numeric(df_raw[outcome_col], errors=\"coerce\")\n",
    "\n",
    "            # Only 0/1 are clean answers; 3 (disputes) and 4 (don't know) \u2192 NaN\n",
    "            baseline_clean = baseline.where(baseline.isin([0, 1]))\n",
    "            outcome_clean  = outcome.where(outcome.isin([0, 1]))\n",
    "\n",
    "            no_disease = (baseline_clean == 0)\n",
    "            develops   = (outcome_clean == 1)\n",
    "\n",
    "            target_vals = (no_disease & develops).astype(float)\n",
    "            # Mark as NaN if outcome is unknown\n",
    "            target_vals[outcome_clean.isna()] = np.nan\n",
    "\n",
    "            targets[f\"target_{disease_name}\"]   = target_vals.values\n",
    "            targets[f\"eligible_{disease_name}\"] = no_disease.astype(int).values\n",
    "\n",
    "    return pd.DataFrame(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_master_features(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Build multi-screening long-format features + targets.\"\"\"\n",
    "    banner(\"PHASE 1-3: BUILDING FEATURES + TARGETS\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for scr in FEATURE_SCREENINGS:\n",
    "        outcome_scr = scr + PREDICTION_HORIZON\n",
    "        if outcome_scr > 18:\n",
    "            continue\n",
    "\n",
    "        # Features for this screening (with lags)\n",
    "        feats = extract_screening_features(df_raw, scr)\n",
    "        feats = add_temporal_features(feats)\n",
    "\n",
    "        # Targets from this screening \u2192 outcome screening\n",
    "        targs = create_targets(df_raw, scr, outcome_scr)\n",
    "\n",
    "        # Merge on person_id\n",
    "        combined = feats.merge(targs, on=\"person_id\", how=\"inner\")\n",
    "        # Internal grouping key (not exposed as a feature)\n",
    "        combined[\"_screening_id\"] = scr\n",
    "        all_data.append(combined)\n",
    "\n",
    "        print(f\"  Screening {scr} \u2192 {outcome_scr}: {len(combined):,} rows, \"\n",
    "              f\"{feats.shape[1]} features\")\n",
    "\n",
    "    master = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\n  TOTAL: {len(master):,} rows\")\n",
    "    return master\n",
    "\n",
    "def get_disease_dataset(master: pd.DataFrame, disease: str):\n",
    "    \"\"\"\n",
    "    Filter master to only eligible patients for this disease,\n",
    "    split group-aware, return X_train/test, y_train/test.\n",
    "    \"\"\"\n",
    "    eligible_col = f\"eligible_{disease}\"\n",
    "    target_col   = f\"target_{disease}\"\n",
    "\n",
    "    # Only eligible (didn't have this disease at baseline)\n",
    "    sub = master[master[eligible_col] == 1].copy()\n",
    "    # Remove rows where outcome is unknown\n",
    "    sub = sub[sub[target_col].notna()].copy()\n",
    "    # Drop rows missing critical features\n",
    "    sub = sub.dropna(subset=[\"age\", \"bmi\"])\n",
    "\n",
    "    y = sub[target_col].astype(int)\n",
    "\n",
    "    # Feature columns: exclude targets, eligibility, metadata\n",
    "    exclude_prefixes = (\"target_\", \"eligible_\")\n",
    "    metadata_cols = {\"person_id\", \"_screening_id\"}\n",
    "    # # Also exclude demographic columns used for fairness audit\n",
    "    # fairness_cols = {\"female\", \"ethnicity\"}\n",
    "\n",
    "    feature_cols = sorted([\n",
    "        c for c in sub.columns\n",
    "        if not c.startswith(exclude_prefixes)\n",
    "        and c not in metadata_cols\n",
    "        # Keep fairness cols as features (they can be predictive)\n",
    "    ])\n",
    "\n",
    "    X = sub[feature_cols]\n",
    "\n",
    "    # Group-aware split: same person never in both train and test\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=sub[\"person_id\"]))\n",
    "\n",
    "    X_train = X.iloc[train_idx].copy()\n",
    "    y_train = y.iloc[train_idx].copy()\n",
    "    X_test  = X.iloc[test_idx].copy()\n",
    "    y_test  = y.iloc[test_idx].copy()\n",
    "\n",
    "    # Fairness demographics for test set\n",
    "    demo_test = sub.iloc[test_idx][[\"person_id\", \"female\", \"ethnicity\", \"age\"]].copy()\n",
    "\n",
    "    return feature_cols, X_train, y_train, X_test, y_test, demo_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Ensure the model directory exists\n",
    "MODEL_DIR = OUTPUT_DIR / \"saved_models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def train_disease_expert(\n",
    "    disease: str,\n",
    "    feature_cols: List[str],\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    ") -> Tuple[Dict, Dict, np.ndarray]:\n",
    "    \n",
    "    banner(f\"EXPERT TRAIN & SAVE: {disease.upper()}\")\n",
    "    \n",
    "    # 1. Calculate Class Weight\n",
    "    neg = (y_train == 0).sum()\n",
    "    pos = (y_train == 1).sum()\n",
    "    spw = neg / max(pos, 1)\n",
    "    print(f\"  Scale_pos_weight: {spw:.2f} | Train Size: {len(X_train):,}\")\n",
    "\n",
    "    # 2. Identify Categorical Columns\n",
    "    cat_cols = [c for c in feature_cols if X_train[c].dtype.name == \"category\"]\n",
    "    cat_indices = [feature_cols.index(c) for c in cat_cols]\n",
    "    if cat_cols:\n",
    "        print(f\"  Categorical features: {len(cat_cols)}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # =========================================================================\n",
    "    print(f\"  [Optuna] Tuning CatBoost for {disease} (Max 3 mins)...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"iterations\": 1000, # Faster for tuning\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10, log=True),\n",
    "            \"loss_function\": \"Logloss\",\n",
    "            \"eval_metric\": \"AUC\",\n",
    "            \"scale_pos_weight\": spw,\n",
    "            \"random_seed\": SEED,\n",
    "            \"verbose\": 0,\n",
    "            \"early_stopping_rounds\": 50,\n",
    "            \"task_type\": \"GPU\", # Enable GPU\n",
    "            \"devices\": \"0\"\n",
    "        }\n",
    "        \n",
    "        # Fit on Train, Eval on Test\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=0,\n",
    "                  cat_features=cat_indices if cat_indices else None)\n",
    "        \n",
    "        preds = model.predict_proba(X_test)[:, 1]\n",
    "        return roc_auc_score(y_test, preds)\n",
    "\n",
    "    # Run Optimization\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(seed=SEED))\n",
    "    study.optimize(objective, n_trials=20, timeout=180) # Stop after 20 trials or 3 mins\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"  [Optuna] Best AUC: {study.best_value:.4f}\")\n",
    "    print(f\"  [Optuna] Params: {best_params}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # =========================================================================\n",
    "    \n",
    "    # 1. CatBoost (With Best Params)\n",
    "    # We increase iterations for the final robust model\n",
    "    final_cat_params = best_params.copy()\n",
    "    final_cat_params.update({\n",
    "        \"iterations\": 3000,\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"scale_pos_weight\": spw,\n",
    "        \"random_seed\": SEED,\n",
    "        \"verbose\": 0,\n",
    "        \"early_stopping_rounds\": 300,\n",
    "        \"task_type\": \"GPU\",\n",
    "        \"devices\": \"0\",\n",
    "        \"use_best_model\": True\n",
    "    })\n",
    "    \n",
    "    cat_model = CatBoostClassifier(**final_cat_params)\n",
    "    cat_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        cat_features=cat_indices if cat_indices else None\n",
    "    )\n",
    "    cat_pred = cat_model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"  CatBoost (Tuned) AUC: {roc_auc_score(y_test, cat_pred):.4f}\")\n",
    "\n",
    "    # 2. LightGBM (Robust CPU Fallback)\n",
    "    try:\n",
    "        lgb_model = lgb.LGBMClassifier(\n",
    "            n_estimators=2000, learning_rate=0.02, num_leaves=63, max_depth=7,\n",
    "            scale_pos_weight=spw, random_state=SEED, n_jobs=-1, verbose=-1,\n",
    "            device=\"gpu\", gpu_platform_id=0, gpu_device_id=0\n",
    "        )\n",
    "        lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "                      callbacks=[lgb.early_stopping(300, verbose=False)],\n",
    "                      categorical_feature=cat_cols if cat_cols else \"auto\")\n",
    "    except Exception:\n",
    "        print(\"  [INFO] LightGBM using CPU fallback.\")\n",
    "        lgb_model = lgb.LGBMClassifier(\n",
    "            n_estimators=2000, learning_rate=0.02, num_leaves=63, max_depth=7,\n",
    "            scale_pos_weight=spw, random_state=SEED, n_jobs=-1, verbose=-1, device=\"cpu\"\n",
    "        )\n",
    "        lgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "                      callbacks=[lgb.early_stopping(300, verbose=False)],\n",
    "                      categorical_feature=cat_cols if cat_cols else \"auto\")\n",
    "        \n",
    "    lgb_pred = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 3. XGBoost (GPU Hist)\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=2000, learning_rate=0.02, max_depth=6, scale_pos_weight=spw,\n",
    "        eval_metric=\"auc\", enable_categorical=True, random_state=SEED, n_jobs=-1,\n",
    "        early_stopping_rounds=300, device=\"cuda\", tree_method=\"hist\", verbosity=0\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    xgb_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 4. Average Ensemble\n",
    "    avg_pred = (cat_pred + lgb_pred + xgb_pred) / 3\n",
    "    avg_auc = roc_auc_score(y_test, avg_pred)\n",
    "    print(f\"  Ensemble Final AUC: {avg_auc:.4f}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # =========================================================================\n",
    "    models = {\n",
    "        \"cat\": cat_model,\n",
    "        \"lgb\": lgb_model,\n",
    "        \"xgb\": xgb_model\n",
    "    }\n",
    "    \n",
    "    # Save the dictionary of models to a single pickle file for this disease\n",
    "    filename = MODEL_DIR / f\"ensemble_{disease}.pkl\"\n",
    "    joblib.dump(models, filename)\n",
    "    print(f\"  [SAVED] Ensemble saved to {filename}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # =========================================================================\n",
    "    preds = {\n",
    "        \"cat\": cat_pred,\n",
    "        \"lgb\": lgb_pred,\n",
    "        \"xgb\": xgb_pred,\n",
    "        \"avg\": avg_pred\n",
    "    }\n",
    "    \n",
    "    results = evaluate_expert(disease, y_test, preds)\n",
    "    \n",
    "    return models, results, avg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_f2_threshold(y_true, y_proba):\n",
    "    best_t, best_f2 = 0.5, 0\n",
    "    for t in np.linspace(0.02, 0.6, 200):\n",
    "        preds = (y_proba >= t).astype(int)\n",
    "        f2 = fbeta_score(y_true, preds, beta=2, zero_division=0)\n",
    "        if f2 > best_f2:\n",
    "            best_f2 = f2\n",
    "            best_t = t\n",
    "    return best_t, best_f2\n",
    "\n",
    "def evaluate_expert(disease: str, y_test, preds: dict) -> dict:\n",
    "    results = {}\n",
    "    for name, proba in preds.items():\n",
    "        roc  = roc_auc_score(y_test, proba)\n",
    "        pr   = average_precision_score(y_test, proba)\n",
    "        bt, bf2 = find_best_f2_threshold(y_test, proba)\n",
    "\n",
    "        y_pred = (proba >= bt).astype(int)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        results[name] = {\n",
    "            \"roc_auc\": round(roc, 4),\n",
    "            \"pr_auc\": round(pr, 4),\n",
    "            \"f2\": round(bf2, 4),\n",
    "            \"precision\": round(prec, 4),\n",
    "            \"recall\": round(rec, 4),\n",
    "            \"threshold\": round(bt, 4),\n",
    "        }\n",
    "        print(f\"  {disease}/{name}: ROC={roc:.4f} PR={pr:.4f} F2={bf2:.4f} \"\n",
    "              f\"P={prec:.4f} R={rec:.4f} t={bt:.3f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_any_onset_from_experts(\n",
    "    master: pd.DataFrame,\n",
    "    all_models: Dict[str, Dict],\n",
    "    all_feature_cols: Dict[str, List[str]],\n",
    "):\n",
    "    \"\"\"\n",
    "    For the test set, combine expert probabilities:\n",
    "      P(any onset) = 1 - \u220f(1 - P_d)  for eligible diseases\n",
    "    \"\"\"\n",
    "    banner(\"META-ENSEMBLE: ANY-DISEASE ONSET\")\n",
    "\n",
    "    # Group by person + screening (using internal _wave key)\n",
    "    # Rebuild predictions disease by disease and combine per person-screening\n",
    "\n",
    "    results_per_ps = {}\n",
    "\n",
    "    for disease, models in all_models.items():\n",
    "        eligible_col = f\"eligible_{disease}\"\n",
    "        target_col   = f\"target_{disease}\"\n",
    "\n",
    "        sub = master[(master[eligible_col] == 1) & (master[target_col].notna())].copy()\n",
    "        sub = sub.dropna(subset=[\"age\", \"bmi\"])\n",
    "\n",
    "        feature_cols = all_feature_cols[disease]\n",
    "        X = sub[feature_cols]\n",
    "\n",
    "        # Get predictions from ensemble mean\n",
    "        lgb_pred = models[\"lgb\"].predict_proba(X)[:, 1]\n",
    "        cat_pred = models[\"cat\"].predict_proba(X)[:, 1]\n",
    "        xgb_pred = models[\"xgb\"].predict_proba(X)[:, 1]\n",
    "        avg_pred = (lgb_pred + cat_pred + xgb_pred) / 3\n",
    "\n",
    "        for i, (pid, w) in enumerate(zip(sub[\"person_id\"].values, sub[\"_screening_id\"].values)):\n",
    "            key = (pid, w)\n",
    "            if key not in results_per_ps:\n",
    "                results_per_ps[key] = {\"probs\": [], \"has_target\": 0, \"any_eligible\": False}\n",
    "            results_per_ps[key][\"probs\"].append(avg_pred[i])\n",
    "            results_per_ps[key][\"any_eligible\"] = True\n",
    "            # Any-onset target: did they develop ANY disease?\n",
    "            if sub.iloc[i][target_col] == 1:\n",
    "                results_per_ps[key][\"has_target\"] = 1\n",
    "\n",
    "    # Compute P(any onset) = 1 - prod(1 - p_d)\n",
    "    y_true_list = []\n",
    "    y_proba_list = []\n",
    "\n",
    "    for key, info in results_per_ps.items():\n",
    "        if not info[\"any_eligible\"]:\n",
    "            continue\n",
    "        probs = info[\"probs\"]\n",
    "        p_no_onset = 1.0\n",
    "        for p in probs:\n",
    "            p_no_onset *= (1 - p)\n",
    "        p_any = 1 - p_no_onset\n",
    "\n",
    "        y_proba_list.append(p_any)\n",
    "        y_true_list.append(info[\"has_target\"])\n",
    "\n",
    "    y_true  = np.array(y_true_list)\n",
    "    y_proba = np.array(y_proba_list)\n",
    "\n",
    "    # Evaluate\n",
    "    roc  = roc_auc_score(y_true, y_proba)\n",
    "    pr   = average_precision_score(y_true, y_proba)\n",
    "    bt, bf2 = find_best_f2_threshold(y_true, y_proba)\n",
    "\n",
    "    print(\"\\n  ANY-ONSET Combined:\")\n",
    "    print(f\"    ROC-AUC:  {roc:.4f}\")\n",
    "    print(f\"    PR-AUC:   {pr:.4f}\")\n",
    "    print(f\"    Best F2:  {bf2:.4f} @ threshold {bt:.3f}\")\n",
    "    print(f\"    Samples:  {len(y_true):,} | Events: {y_true.sum():,.0f} ({y_true.mean():.2%})\")\n",
    "\n",
    "    return {\"roc_auc\": roc, \"pr_auc\": pr, \"f2\": bf2, \"threshold\": bt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explain_expert(models, X_test, feature_cols, disease, top_n=20):\n",
    "    \"\"\"SHAP summary for the LightGBM expert of this disease.\"\"\"\n",
    "    try:\n",
    "        import shap\n",
    "        import matplotlib\n",
    "        matplotlib.use(\"Agg\")\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        model = models[\"lgb\"]\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1]\n",
    "\n",
    "        # Summary plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_test, max_display=top_n, show=False)\n",
    "        plt.title(f\"SHAP \u2014 {disease.upper()} Expert\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / f\"shap_{disease}.png\", dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"  Saved SHAP plot: shap_{disease}.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"  SHAP failed for {disease}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_importance(all_models, all_feature_cols):\n",
    "    \"\"\"Export feature importance per disease expert.\"\"\"\n",
    "    rows = []\n",
    "    for disease, models in all_models.items():\n",
    "        feat_cols = all_feature_cols[disease]\n",
    "        lgb_imp = models[\"lgb\"].feature_importances_\n",
    "        cat_imp = models[\"cat\"].get_feature_importance()\n",
    "        xgb_imp = models[\"xgb\"].feature_importances_\n",
    "\n",
    "        for i, feat in enumerate(feat_cols):\n",
    "            rows.append({\n",
    "                \"disease\": disease,\n",
    "                \"feature\": feat,\n",
    "                \"lgb\": lgb_imp[i],\n",
    "                \"cat\": cat_imp[i],\n",
    "                \"xgb\": xgb_imp[i],\n",
    "                \"avg\": (lgb_imp[i] + cat_imp[i] + xgb_imp[i]) / 3,\n",
    "            })\n",
    "\n",
    "    df_imp = pd.DataFrame(rows)\n",
    "    df_imp.to_csv(OUTPUT_DIR / \"feature_importance_experts.csv\", index=False)\n",
    "    print(f\"\\n  Saved feature_importance_experts.csv ({len(df_imp)} rows)\")\n",
    "\n",
    "    # Print top-10 per disease\n",
    "    for disease in DISEASE_MAP:\n",
    "        sub = df_imp[df_imp[\"disease\"] == disease].nlargest(10, \"avg\")\n",
    "        print(f\"\\n  TOP-10 {disease.upper()}:\")\n",
    "        for _, row in sub.iterrows():\n",
    "            print(f\"    {row['feature']:<30} avg={row['avg']:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fairness_audit(disease, y_test, y_proba, threshold, demo_test):\n",
    "    \"\"\"Quick fairness check across demographics.\"\"\"\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n  Fairness \u2014 {disease.upper()}\")\n",
    "\n",
    "    # Gender\n",
    "    for gval, gname in {0: \"Male\", 1: \"Female\"}.items():\n",
    "        mask = demo_test[\"female\"].values == gval\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        g_rec = recall_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_prec = precision_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_f2  = fbeta_score(y_test.values[mask], y_pred[mask], beta=2, zero_division=0)\n",
    "        print(f\"    {gname:<12}: F2={g_f2:.4f}  P={g_prec:.4f}  R={g_rec:.4f} (n={mask.sum():,})\")\n",
    "\n",
    "    # Ethnicity\n",
    "    for eth in [\"White\", \"Black\", \"Hispanic\", \"Other\"]:\n",
    "        mask = demo_test[\"ethnicity\"].values == eth\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        g_rec = recall_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_prec = precision_score(y_test.values[mask], y_pred[mask], zero_division=0)\n",
    "        g_f2  = fbeta_score(y_test.values[mask], y_pred[mask], beta=2, zero_division=0)\n",
    "        print(f\"    {eth:<12}: F2={g_f2:.4f}  P={g_prec:.4f}  R={g_rec:.4f} (n={mask.sum():,})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  HYBRID DISEASE-EXPERT ENSEMBLE\n",
      "=================================================================\n",
      "  Data:    /teamspace/studios/this_studio/data/extracted/randhrs1992_2022v1.parquet\n",
      "  Output:  /teamspace/studios/this_studio/output_hybrid\n",
      "  Horizon: 2 screenings (~4 years)\n",
      "  Diseases: ['diabetes', 'cvd', 'stroke', 'lung', 'cancer', 'hibp', 'arthritis', 'psychiatric', 'memory']\n",
      "\n",
      "  Loading parquet data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (45234, 19880)\n",
      "\n",
      "=================================================================\n",
      "  PHASE 1-3: BUILDING FEATURES + TARGETS\n",
      "=================================================================\n",
      "  Screening 5 \u2192 7: 45,234 rows, 150 features\n",
      "  Screening 6 \u2192 8: 45,234 rows, 150 features\n",
      "  Screening 7 \u2192 9: 45,234 rows, 150 features\n",
      "  Screening 8 \u2192 10: 45,234 rows, 150 features\n",
      "  Screening 9 \u2192 11: 45,234 rows, 150 features\n",
      "  Screening 10 \u2192 12: 45,234 rows, 150 features\n",
      "  Screening 11 \u2192 13: 45,234 rows, 150 features\n",
      "  Screening 12 \u2192 14: 45,234 rows, 150 features\n",
      "\n",
      "  TOTAL: 361,872 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 10:48:10,181]\u001b[0m A new study created in memory with name: no-name-15003216-7650-4340-ba8c-96a8124b21c0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: DIABETES\n",
      "=================================================================\n",
      "  Scale_pos_weight: 13.14 | Train Size: 76,088\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for diabetes (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:16,771]\u001b[0m Trial 0 finished with value: 0.7022947139127821 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.7022947139127821.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:19,948]\u001b[0m Trial 1 finished with value: 0.7029537533963465 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.7029537533963465.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:29,413]\u001b[0m Trial 2 finished with value: 0.7015598231102005 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 1 with value: 0.7029537533963465.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:32,814]\u001b[0m Trial 3 finished with value: 0.7031419785910804 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 3 with value: 0.7031419785910804.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:35,881]\u001b[0m Trial 4 finished with value: 0.704189698494567 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:43,497]\u001b[0m Trial 5 finished with value: 0.7032884038872063 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:49,449]\u001b[0m Trial 6 finished with value: 0.7039187530596017 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:48:56,720]\u001b[0m Trial 7 finished with value: 0.7037798668233451 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:00,132]\u001b[0m Trial 8 finished with value: 0.6997033715010804 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:03,608]\u001b[0m Trial 9 finished with value: 0.701319243333042 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:05,530]\u001b[0m Trial 10 finished with value: 0.7002844654823307 and parameters: {'learning_rate': 0.0950596200453932, 'depth': 6, 'l2_leaf_reg': 2.0444908868342817}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:08,470]\u001b[0m Trial 11 finished with value: 0.7027444188339789 and parameters: {'learning_rate': 0.07421533288534989, 'depth': 5, 'l2_leaf_reg': 5.410013444815476}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:13,340]\u001b[0m Trial 12 finished with value: 0.7031863333933106 and parameters: {'learning_rate': 0.019292311482059607, 'depth': 5, 'l2_leaf_reg': 2.1997804987095217}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:16,482]\u001b[0m Trial 13 finished with value: 0.7034814038198574 and parameters: {'learning_rate': 0.054752700564657614, 'depth': 4, 'l2_leaf_reg': 4.979157893318766}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:19,836]\u001b[0m Trial 14 finished with value: 0.7021852718936813 and parameters: {'learning_rate': 0.04946576171819757, 'depth': 6, 'l2_leaf_reg': 7.9114438155504185}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:23,850]\u001b[0m Trial 15 finished with value: 0.7010484654327405 and parameters: {'learning_rate': 0.020810678987912962, 'depth': 6, 'l2_leaf_reg': 1.0565925458227765}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:26,395]\u001b[0m Trial 16 finished with value: 0.7011636455140751 and parameters: {'learning_rate': 0.06827023261398137, 'depth': 7, 'l2_leaf_reg': 2.8299097567914315}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:30,906]\u001b[0m Trial 17 finished with value: 0.7033463289972012 and parameters: {'learning_rate': 0.03371156334545309, 'depth': 5, 'l2_leaf_reg': 3.911737146986698}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:33,640]\u001b[0m Trial 18 finished with value: 0.6991949875639019 and parameters: {'learning_rate': 0.09551459157311994, 'depth': 7, 'l2_leaf_reg': 1.614715865158338}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:49:37,762]\u001b[0m Trial 19 finished with value: 0.7029395967172588 and parameters: {'learning_rate': 0.042958663514950576, 'depth': 4, 'l2_leaf_reg': 6.877694110233234}. Best is trial 4 with value: 0.704189698494567.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.7042\n",
      "  [Optuna] Params: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.7042\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.7034\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_diabetes.pkl\n",
      "  diabetes/cat: ROC=0.7042 PR=0.1383 F2=0.3565 P=0.1225 R=0.6819 t=0.498\n",
      "  diabetes/lgb: ROC=0.6840 PR=0.1272 F2=0.3396 P=0.1183 R=0.6377 t=0.090\n",
      "  diabetes/xgb: ROC=0.6981 PR=0.1398 F2=0.3551 P=0.1187 R=0.7073 t=0.460\n",
      "  diabetes/avg: ROC=0.7034 PR=0.1405 F2=0.3593 P=0.1257 R=0.6707 t=0.361\n",
      "\n",
      "  Fairness \u2014 DIABETES\n",
      "    Male        : F2=0.3573  P=0.1231  R=0.6813 (n=7,670)\n",
      "    Female      : F2=0.3608  P=0.1278  R=0.6628 (n=11,537)\n",
      "    White       : F2=0.3229  P=0.1159  R=0.5837 (n=14,355)\n",
      "    Black       : F2=0.3817  P=0.1242  R=0.7930 (n=2,604)\n",
      "    Hispanic    : F2=0.4325  P=0.1481  R=0.8318 (n=1,789)\n",
      "    Other       : F2=0.4952  P=0.2071  R=0.7593 (n=459)\n",
      "  Saved SHAP plot: shap_diabetes.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 10:50:07,121]\u001b[0m A new study created in memory with name: no-name-cf4eacd4-a3f0-432d-99d1-9b5bb4e78ace\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: CVD\n",
      "=================================================================\n",
      "  Scale_pos_weight: 9.96 | Train Size: 73,925\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for cvd (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:11,143]\u001b[0m Trial 0 finished with value: 0.6868345707640341 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.6868345707640341.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:13,504]\u001b[0m Trial 1 finished with value: 0.6887310770675531 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.6887310770675531.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:19,977]\u001b[0m Trial 2 finished with value: 0.6883868488832483 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 1 with value: 0.6887310770675531.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:22,583]\u001b[0m Trial 3 finished with value: 0.6894125882725192 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 3 with value: 0.6894125882725192.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:24,541]\u001b[0m Trial 4 finished with value: 0.6900899800421871 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:28,395]\u001b[0m Trial 5 finished with value: 0.6888765169650262 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:31,562]\u001b[0m Trial 6 finished with value: 0.6889756898164632 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:36,429]\u001b[0m Trial 7 finished with value: 0.6889817498121912 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:38,802]\u001b[0m Trial 8 finished with value: 0.6879753990047581 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:41,692]\u001b[0m Trial 9 finished with value: 0.6880434377770193 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:43,562]\u001b[0m Trial 10 finished with value: 0.6892407805846452 and parameters: {'learning_rate': 0.0950596200453932, 'depth': 6, 'l2_leaf_reg': 2.0444908868342817}. Best is trial 4 with value: 0.6900899800421871.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:46,042]\u001b[0m Trial 11 finished with value: 0.6901254208037202 and parameters: {'learning_rate': 0.06742696415524822, 'depth': 4, 'l2_leaf_reg': 8.0847164965543}. Best is trial 11 with value: 0.6901254208037202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:48,332]\u001b[0m Trial 12 finished with value: 0.688116872669072 and parameters: {'learning_rate': 0.08179207517647072, 'depth': 4, 'l2_leaf_reg': 8.850379152651257}. Best is trial 11 with value: 0.6901254208037202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:50,927]\u001b[0m Trial 13 finished with value: 0.6905665067849143 and parameters: {'learning_rate': 0.06205043932050714, 'depth': 5, 'l2_leaf_reg': 5.96648250185325}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:53,361]\u001b[0m Trial 14 finished with value: 0.6899695291158623 and parameters: {'learning_rate': 0.055294034071251726, 'depth': 4, 'l2_leaf_reg': 6.364835213898073}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:55,955]\u001b[0m Trial 15 finished with value: 0.6900585565811928 and parameters: {'learning_rate': 0.04898649966092548, 'depth': 5, 'l2_leaf_reg': 6.2222655351757075}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:50:58,459]\u001b[0m Trial 16 finished with value: 0.687965372775871 and parameters: {'learning_rate': 0.07187208995776222, 'depth': 6, 'l2_leaf_reg': 7.4929317356059215}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:00,831]\u001b[0m Trial 17 finished with value: 0.6867469050954963 and parameters: {'learning_rate': 0.09971721337974593, 'depth': 7, 'l2_leaf_reg': 4.9302745428887595}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:03,238]\u001b[0m Trial 18 finished with value: 0.6898898980484022 and parameters: {'learning_rate': 0.059145813889703885, 'depth': 4, 'l2_leaf_reg': 9.868749139630006}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:05,702]\u001b[0m Trial 19 finished with value: 0.6891490125032692 and parameters: {'learning_rate': 0.040372632080937235, 'depth': 6, 'l2_leaf_reg': 7.563306874066247}. Best is trial 13 with value: 0.6905665067849143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.6906\n",
      "  [Optuna] Params: {'learning_rate': 0.06205043932050714, 'depth': 5, 'l2_leaf_reg': 5.96648250185325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.6906\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.6902\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_cvd.pkl\n",
      "  cvd/cat: ROC=0.6906 PR=0.1810 F2=0.4057 P=0.1351 R=0.8127 t=0.422\n",
      "  cvd/lgb: ROC=0.6735 PR=0.1689 F2=0.3931 P=0.1367 R=0.7400 t=0.113\n",
      "  cvd/xgb: ROC=0.6856 PR=0.1821 F2=0.3998 P=0.1328 R=0.8041 t=0.422\n",
      "  cvd/avg: ROC=0.6902 PR=0.1843 F2=0.4052 P=0.1384 R=0.7824 t=0.329\n",
      "\n",
      "  Fairness \u2014 CVD\n",
      "    Male        : F2=0.4147  P=0.1426  R=0.7928 (n=6,887)\n",
      "    Female      : F2=0.3984  P=0.1353  R=0.7750 (n=11,682)\n",
      "    White       : F2=0.4253  P=0.1466  R=0.8108 (n=12,884)\n",
      "    Black       : F2=0.3466  P=0.1119  R=0.7288 (n=2,988)\n",
      "    Hispanic    : F2=0.3379  P=0.1155  R=0.6519 (n=2,229)\n",
      "    Other       : F2=0.3834  P=0.1420  R=0.6667 (n=468)\n",
      "  Saved SHAP plot: shap_cvd.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 10:51:30,893]\u001b[0m A new study created in memory with name: no-name-b90887ed-6cce-411f-ab1f-a27024a1d01d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: STROKE\n",
      "=================================================================\n",
      "  Scale_pos_weight: 31.15 | Train Size: 89,527\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for stroke (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:32,938]\u001b[0m Trial 0 finished with value: 0.6902566051340514 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.6902566051340514.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:35,275]\u001b[0m Trial 1 finished with value: 0.6931445158454469 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.6931445158454469.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:38,775]\u001b[0m Trial 2 finished with value: 0.6885337649873086 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 1 with value: 0.6931445158454469.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:41,130]\u001b[0m Trial 3 finished with value: 0.6928705368283556 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 1 with value: 0.6931445158454469.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:43,133]\u001b[0m Trial 4 finished with value: 0.6932914860665194 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:46,602]\u001b[0m Trial 5 finished with value: 0.6924602111282712 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:49,692]\u001b[0m Trial 6 finished with value: 0.6925733484255241 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:51,985]\u001b[0m Trial 7 finished with value: 0.6916815802194864 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:54,516]\u001b[0m Trial 8 finished with value: 0.6883806371741009 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:56,190]\u001b[0m Trial 9 finished with value: 0.6916557995315358 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:57,825]\u001b[0m Trial 10 finished with value: 0.6887626447169484 and parameters: {'learning_rate': 0.0950596200453932, 'depth': 6, 'l2_leaf_reg': 2.0444908868342817}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:51:59,518]\u001b[0m Trial 11 finished with value: 0.6931538537324211 and parameters: {'learning_rate': 0.06742696415524822, 'depth': 4, 'l2_leaf_reg': 1.0932643838131673}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:01,272]\u001b[0m Trial 12 finished with value: 0.6926986994082758 and parameters: {'learning_rate': 0.08179207517647072, 'depth': 4, 'l2_leaf_reg': 1.089552980317502}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:03,236]\u001b[0m Trial 13 finished with value: 0.6919213203176722 and parameters: {'learning_rate': 0.06205043932050714, 'depth': 5, 'l2_leaf_reg': 2.124962948569709}. Best is trial 4 with value: 0.6932914860665194.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:05,509]\u001b[0m Trial 14 finished with value: 0.6935189786462824 and parameters: {'learning_rate': 0.06512883388592991, 'depth': 6, 'l2_leaf_reg': 1.4897720904073855}. Best is trial 14 with value: 0.6935189786462824.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:07,369]\u001b[0m Trial 15 finished with value: 0.6915713863866059 and parameters: {'learning_rate': 0.04619736796459674, 'depth': 6, 'l2_leaf_reg': 1.6514049568425577}. Best is trial 14 with value: 0.6935189786462824.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:09,535]\u001b[0m Trial 16 finished with value: 0.6873469736855639 and parameters: {'learning_rate': 0.06644526695314784, 'depth': 7, 'l2_leaf_reg': 2.6619506306413276}. Best is trial 14 with value: 0.6935189786462824.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:11,563]\u001b[0m Trial 17 finished with value: 0.686516375405792 and parameters: {'learning_rate': 0.09972163683018213, 'depth': 7, 'l2_leaf_reg': 1.434557654860981}. Best is trial 14 with value: 0.6935189786462824.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:13,796]\u001b[0m Trial 18 finished with value: 0.6910883537332332 and parameters: {'learning_rate': 0.050253069663926536, 'depth': 6, 'l2_leaf_reg': 6.203576039571512}. Best is trial 14 with value: 0.6935189786462824.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:16,586]\u001b[0m Trial 19 finished with value: 0.6925397184992472 and parameters: {'learning_rate': 0.020744289823126972, 'depth': 5, 'l2_leaf_reg': 1.7588688957001701}. Best is trial 14 with value: 0.6935189786462824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.6935\n",
      "  [Optuna] Params: {'learning_rate': 0.06512883388592991, 'depth': 6, 'l2_leaf_reg': 1.4897720904073855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.6935\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.6922\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_stroke.pkl\n",
      "  stroke/cat: ROC=0.6935 PR=0.0658 F2=0.2072 P=0.0634 R=0.4781 t=0.583\n",
      "  stroke/lgb: ROC=0.6642 PR=0.0539 F2=0.1985 P=0.0534 R=0.6170 t=0.043\n",
      "  stroke/xgb: ROC=0.6841 PR=0.0670 F2=0.1981 P=0.0514 R=0.6915 t=0.437\n",
      "  stroke/avg: ROC=0.6922 PR=0.0677 F2=0.2041 P=0.0566 R=0.5863 t=0.355\n",
      "\n",
      "  Fairness \u2014 STROKE\n",
      "    Male        : F2=0.1924  P=0.0534  R=0.5524 (n=9,490)\n",
      "    Female      : F2=0.2140  P=0.0593  R=0.6152 (n=12,800)\n",
      "    White       : F2=0.2089  P=0.0588  R=0.5769 (n=15,656)\n",
      "    Black       : F2=0.2184  P=0.0594  R=0.6583 (n=3,562)\n",
      "    Hispanic    : F2=0.1493  P=0.0388  R=0.5167 (n=2,540)\n",
      "    Other       : F2=0.1923  P=0.0517  R=0.6000 (n=532)\n",
      "  Saved SHAP plot: shap_stroke.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 10:52:44,446]\u001b[0m A new study created in memory with name: no-name-42b06524-d164-439a-866a-cf7c72e2b2b3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: LUNG\n",
      "=================================================================\n",
      "  Scale_pos_weight: 25.88 | Train Size: 86,700\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for lung (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:49,379]\u001b[0m Trial 0 finished with value: 0.7288797737422679 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.7288797737422679.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:52:53,936]\u001b[0m Trial 1 finished with value: 0.7304645856430719 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.7304645856430719.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:00,309]\u001b[0m Trial 2 finished with value: 0.7311534755408182 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 2 with value: 0.7311534755408182.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:03,483]\u001b[0m Trial 3 finished with value: 0.7300962851429695 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 2 with value: 0.7311534755408182.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:05,642]\u001b[0m Trial 4 finished with value: 0.7304429209077719 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 2 with value: 0.7311534755408182.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:15,470]\u001b[0m Trial 5 finished with value: 0.7333314508544607 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 5 with value: 0.7333314508544607.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:21,005]\u001b[0m Trial 6 finished with value: 0.7327959789277587 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 5 with value: 0.7333314508544607.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:26,892]\u001b[0m Trial 7 finished with value: 0.7310066300175619 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 5 with value: 0.7333314508544607.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:31,186]\u001b[0m Trial 8 finished with value: 0.7350087638722769 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:34,552]\u001b[0m Trial 9 finished with value: 0.7327924492798727 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:36,479]\u001b[0m Trial 10 finished with value: 0.7285516077728689 and parameters: {'learning_rate': 0.08813259224734667, 'depth': 7, 'l2_leaf_reg': 2.0891588142634214}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:42,594]\u001b[0m Trial 11 finished with value: 0.7337214160898634 and parameters: {'learning_rate': 0.017767459364064066, 'depth': 7, 'l2_leaf_reg': 2.6706459046349726}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:47,956]\u001b[0m Trial 12 finished with value: 0.7319032822925964 and parameters: {'learning_rate': 0.02114447926570448, 'depth': 7, 'l2_leaf_reg': 2.161698773875608}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:54,686]\u001b[0m Trial 13 finished with value: 0.7318500941503145 and parameters: {'learning_rate': 0.017041266654359857, 'depth': 7, 'l2_leaf_reg': 1.0226313101716986}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:53:58,820]\u001b[0m Trial 14 finished with value: 0.7339546771303281 and parameters: {'learning_rate': 0.038067053557765046, 'depth': 6, 'l2_leaf_reg': 1.669195617418106}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:02,857]\u001b[0m Trial 15 finished with value: 0.7333528721657688 and parameters: {'learning_rate': 0.04371503521825954, 'depth': 6, 'l2_leaf_reg': 1.6514049568425577}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:06,166]\u001b[0m Trial 16 finished with value: 0.7326514459324276 and parameters: {'learning_rate': 0.03251385359753848, 'depth': 6, 'l2_leaf_reg': 1.7357790018773407}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:08,617]\u001b[0m Trial 17 finished with value: 0.7231431526595836 and parameters: {'learning_rate': 0.056735822297115115, 'depth': 8, 'l2_leaf_reg': 1.220025538690605}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:13,146]\u001b[0m Trial 18 finished with value: 0.7330893656942812 and parameters: {'learning_rate': 0.034643367972034926, 'depth': 7, 'l2_leaf_reg': 6.203576039571512}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:15,465]\u001b[0m Trial 19 finished with value: 0.7297436246343619 and parameters: {'learning_rate': 0.09908696623769005, 'depth': 6, 'l2_leaf_reg': 2.8611679835739596}. Best is trial 8 with value: 0.7350087638722769.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.7350\n",
      "  [Optuna] Params: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.7350\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.7365\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_lung.pkl\n",
      "  lung/cat: ROC=0.7350 PR=0.1032 F2=0.2643 P=0.0913 R=0.5019 t=0.574\n",
      "  lung/lgb: ROC=0.7022 PR=0.0871 F2=0.2451 P=0.0717 R=0.6207 t=0.049\n",
      "  lung/xgb: ROC=0.7325 PR=0.1008 F2=0.2586 P=0.0989 R=0.4336 t=0.591\n",
      "  lung/avg: ROC=0.7365 PR=0.1023 F2=0.2644 P=0.1104 R=0.4058 t=0.425\n",
      "\n",
      "  Fairness \u2014 LUNG\n",
      "    Male        : F2=0.2713  P=0.1120  R=0.4209 (n=8,611)\n",
      "    Female      : F2=0.2602  P=0.1094  R=0.3968 (n=12,954)\n",
      "    White       : F2=0.2868  P=0.1241  R=0.4266 (n=15,191)\n",
      "    Black       : F2=0.2264  P=0.0830  R=0.3983 (n=3,502)\n",
      "    Hispanic    : F2=0.1397  P=0.0528  R=0.2373 (n=2,359)\n",
      "    Other       : F2=0.2890  P=0.1639  R=0.3571 (n=513)\n",
      "  Saved SHAP plot: shap_lung.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 10:54:45,815]\u001b[0m A new study created in memory with name: no-name-51890378-e81b-4ade-8b05-09545a639965\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: CANCER\n",
      "=================================================================\n",
      "  Scale_pos_weight: 19.02 | Train Size: 83,170\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for cancer (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:48,094]\u001b[0m Trial 0 finished with value: 0.5969541828481567 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.5969541828481567.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:51,192]\u001b[0m Trial 1 finished with value: 0.6015576312917037 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:54,013]\u001b[0m Trial 2 finished with value: 0.5975657346926408 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:56,306]\u001b[0m Trial 3 finished with value: 0.5975798557001364 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:54:58,045]\u001b[0m Trial 4 finished with value: 0.5986842868161785 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:01,687]\u001b[0m Trial 5 finished with value: 0.598933415054378 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:04,378]\u001b[0m Trial 6 finished with value: 0.5986655834949923 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:05,920]\u001b[0m Trial 7 finished with value: 0.5961410559595889 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:07,901]\u001b[0m Trial 8 finished with value: 0.5978434790122552 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 1 with value: 0.6015576312917037.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:09,875]\u001b[0m Trial 9 finished with value: 0.6023794084663202 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:11,708]\u001b[0m Trial 10 finished with value: 0.5928943464348851 and parameters: {'learning_rate': 0.08813259224734667, 'depth': 7, 'l2_leaf_reg': 1.0175302269298823}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:14,744]\u001b[0m Trial 11 finished with value: 0.6011971715341436 and parameters: {'learning_rate': 0.04363130402754645, 'depth': 4, 'l2_leaf_reg': 1.0932643838131673}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:16,445]\u001b[0m Trial 12 finished with value: 0.5998138972783675 and parameters: {'learning_rate': 0.04077664244287205, 'depth': 6, 'l2_leaf_reg': 1.8528715550580097}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:18,133]\u001b[0m Trial 13 finished with value: 0.5991904688249301 and parameters: {'learning_rate': 0.020092051631560998, 'depth': 6, 'l2_leaf_reg': 2.2703416859188765}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:21,844]\u001b[0m Trial 14 finished with value: 0.60133319143747 and parameters: {'learning_rate': 0.03759702401083852, 'depth': 4, 'l2_leaf_reg': 1.191375703827827}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:24,035]\u001b[0m Trial 15 finished with value: 0.6014037029583418 and parameters: {'learning_rate': 0.060300144638271824, 'depth': 6, 'l2_leaf_reg': 1.4325480288460595}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:27,996]\u001b[0m Trial 16 finished with value: 0.6012024084640757 and parameters: {'learning_rate': 0.03447586373397595, 'depth': 7, 'l2_leaf_reg': 2.247586190954937}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:29,639]\u001b[0m Trial 17 finished with value: 0.5990194035735313 and parameters: {'learning_rate': 0.020978149573920166, 'depth': 6, 'l2_leaf_reg': 1.3550631820520582}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:31,227]\u001b[0m Trial 18 finished with value: 0.597857950707023 and parameters: {'learning_rate': 0.08796831394171943, 'depth': 4, 'l2_leaf_reg': 1.9242342515335924}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:55:33,619]\u001b[0m Trial 19 finished with value: 0.5971393924862026 and parameters: {'learning_rate': 0.05152023107375697, 'depth': 7, 'l2_leaf_reg': 2.8611679835739596}. Best is trial 9 with value: 0.6023794084663202.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.6024\n",
      "  [Optuna] Params: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.6024\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.5946\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_cancer.pkl\n",
      "  cancer/cat: ROC=0.6024 PR=0.0732 F2=0.2334 P=0.0625 R=0.7388 t=0.466\n",
      "  cancer/lgb: ROC=0.5795 PR=0.0663 F2=0.2245 P=0.0601 R=0.7119 t=0.058\n",
      "  cancer/xgb: ROC=0.5865 PR=0.0761 F2=0.2286 P=0.0623 R=0.6877 t=0.425\n",
      "  cancer/avg: ROC=0.5946 PR=0.0768 F2=0.2309 P=0.0628 R=0.6989 t=0.317\n",
      "\n",
      "  Fairness \u2014 CANCER\n",
      "    Male        : F2=0.2695  P=0.0725  R=0.8406 (n=8,638)\n",
      "    Female      : F2=0.1917  P=0.0527  R=0.5628 (n=12,314)\n",
      "    White       : F2=0.2395  P=0.0642  R=0.7542 (n=14,606)\n",
      "    Black       : F2=0.2186  P=0.0610  R=0.6190 (n=3,387)\n",
      "    Hispanic    : F2=0.1328  P=0.0401  R=0.3151 (n=2,321)\n",
      "    Other       : F2=0.2217  P=0.0783  R=0.4091 (n=638)\n",
      "  Saved SHAP plot: shap_cancer.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 10:56:00,253]\u001b[0m A new study created in memory with name: no-name-750ef435-16c1-42ef-8a0f-24f15af04cd5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: HIBP\n",
      "=================================================================\n",
      "  Scale_pos_weight: 4.04 | Train Size: 41,274\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for hibp (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:56:11,655]\u001b[0m Trial 0 finished with value: 0.6162841696904284 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.6162841696904284.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:56:16,939]\u001b[0m Trial 1 finished with value: 0.6171682205606326 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.6171682205606326.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:57:15,695]\u001b[0m Trial 2 finished with value: 0.6194850374094351 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:57:24,280]\u001b[0m Trial 3 finished with value: 0.6189196353970655 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:57:29,149]\u001b[0m Trial 4 finished with value: 0.6163325143732232 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:57:41,345]\u001b[0m Trial 5 finished with value: 0.6169853746979197 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:57:54,850]\u001b[0m Trial 6 finished with value: 0.6192111236558758 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:58:07,401]\u001b[0m Trial 7 finished with value: 0.6167602198410839 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:58:16,681]\u001b[0m Trial 8 finished with value: 0.6166900401669164 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:58:25,846]\u001b[0m Trial 9 finished with value: 0.6173350896003901 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 2 with value: 0.6194850374094351.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 10:59:40,956]\u001b[0m Trial 10 finished with value: 0.6196047452347646 and parameters: {'learning_rate': 0.01048407718678713, 'depth': 8, 'l2_leaf_reg': 7.136283648418459}. Best is trial 10 with value: 0.6196047452347646.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.6196\n",
      "  [Optuna] Params: {'learning_rate': 0.01048407718678713, 'depth': 8, 'l2_leaf_reg': 7.136283648418459}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.6195\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.6180\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_hibp.pkl\n",
      "  hibp/cat: ROC=0.6195 PR=0.2716 F2=0.5634 P=0.2177 R=0.9343 t=0.346\n",
      "  hibp/lgb: ROC=0.5984 PR=0.2503 F2=0.5588 P=0.2050 R=0.9829 t=0.201\n",
      "  hibp/xgb: ROC=0.6135 PR=0.2686 F2=0.5620 P=0.2164 R=0.9353 t=0.323\n",
      "  hibp/avg: ROC=0.6180 PR=0.2713 F2=0.5639 P=0.2164 R=0.9422 t=0.291\n",
      "\n",
      "  Fairness \u2014 HIBP\n",
      "    Male        : F2=0.5711  P=0.2194  R=0.9529 (n=4,265)\n",
      "    Female      : F2=0.5583  P=0.2140  R=0.9339 (n=6,056)\n",
      "    White       : F2=0.5433  P=0.2036  R=0.9324 (n=7,818)\n",
      "    Black       : F2=0.6357  P=0.2637  R=0.9821 (n=1,078)\n",
      "    Hispanic    : F2=0.6100  P=0.2456  R=0.9695 (n=1,134)\n",
      "    Other       : F2=0.5677  P=0.2355  R=0.8769 (n=291)\n",
      "  Saved SHAP plot: shap_hibp.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 11:01:50,748]\u001b[0m A new study created in memory with name: no-name-bc780ac1-8084-4129-b3b8-5ec563b2f8c6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: ARTHRITIS\n",
      "=================================================================\n",
      "  Scale_pos_weight: 3.93 | Train Size: 39,069\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for arthritis (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:02:24,344]\u001b[0m Trial 0 finished with value: 0.6471673636622691 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.6471673636622691.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:02:34,441]\u001b[0m Trial 1 finished with value: 0.6469619463505927 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 0 with value: 0.6471673636622691.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:03:31,269]\u001b[0m Trial 2 finished with value: 0.6473925587055136 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 2 with value: 0.6473925587055136.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:03:38,491]\u001b[0m Trial 3 finished with value: 0.6471815962354535 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 2 with value: 0.6473925587055136.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:03:47,251]\u001b[0m Trial 4 finished with value: 0.6477500365826421 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 4 with value: 0.6477500365826421.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:04:01,640]\u001b[0m Trial 5 finished with value: 0.6464417488813412 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 4 with value: 0.6477500365826421.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:04:11,733]\u001b[0m Trial 6 finished with value: 0.6472058100937286 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 4 with value: 0.6477500365826421.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:04:34,201]\u001b[0m Trial 7 finished with value: 0.6466356445861541 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 4 with value: 0.6477500365826421.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:04:51,765]\u001b[0m Trial 8 finished with value: 0.6453677133153116 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 4 with value: 0.6477500365826421.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.6478\n",
      "  [Optuna] Params: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.6476\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.6461\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_arthritis.pkl\n",
      "  arthritis/cat: ROC=0.6476 PR=0.3055 F2=0.5648 P=0.2125 R=0.9649 t=0.326\n",
      "  arthritis/lgb: ROC=0.6258 PR=0.2822 F2=0.5586 P=0.2020 R=1.0000 t=0.195\n",
      "  arthritis/xgb: ROC=0.6393 PR=0.3009 F2=0.5612 P=0.2054 R=0.9901 t=0.297\n",
      "  arthritis/avg: ROC=0.6461 PR=0.3058 F2=0.5629 P=0.2077 R=0.9832 t=0.276\n",
      "\n",
      "  Fairness \u2014 ARTHRITIS\n",
      "    Male        : F2=0.5157  P=0.1785  R=0.9771 (n=4,825)\n",
      "    Female      : F2=0.6007  P=0.2340  R=0.9875 (n=5,215)\n",
      "    White       : F2=0.5622  P=0.2070  R=0.9843 (n=6,952)\n",
      "    Black       : F2=0.5947  P=0.2288  R=0.9906 (n=1,431)\n",
      "    Hispanic    : F2=0.5480  P=0.1997  R=0.9720 (n=1,311)\n",
      "    Other       : F2=0.4826  P=0.1613  R=0.9615 (n=346)\n",
      "  Saved SHAP plot: shap_arthritis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 11:05:21,114]\u001b[0m A new study created in memory with name: no-name-1df674e7-49e3-4843-85c2-8054ad10ec02\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: PSYCHIATRIC\n",
      "=================================================================\n",
      "  Scale_pos_weight: 18.96 | Train Size: 78,618\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for psychiatric (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:05:25,950]\u001b[0m Trial 0 finished with value: 0.7273952403622614 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.7273952403622614.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:05:30,794]\u001b[0m Trial 1 finished with value: 0.7291497246360437 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.7291497246360437.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:05:40,356]\u001b[0m Trial 2 finished with value: 0.7262806554273468 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 1 with value: 0.7291497246360437.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:05:44,001]\u001b[0m Trial 3 finished with value: 0.7285028786786976 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 1 with value: 0.7291497246360437.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:05:46,896]\u001b[0m Trial 4 finished with value: 0.7285098831856637 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 1 with value: 0.7291497246360437.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:05:58,360]\u001b[0m Trial 5 finished with value: 0.7301525847904252 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 5 with value: 0.7301525847904252.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:04,979]\u001b[0m Trial 6 finished with value: 0.7299662996382201 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 5 with value: 0.7301525847904252.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:16,389]\u001b[0m Trial 7 finished with value: 0.7308668708355023 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:20,923]\u001b[0m Trial 8 finished with value: 0.725224885195552 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:26,580]\u001b[0m Trial 9 finished with value: 0.7267148769707557 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:32,490]\u001b[0m Trial 10 finished with value: 0.7274226216167653 and parameters: {'learning_rate': 0.016129423372474243, 'depth': 6, 'l2_leaf_reg': 2.256804170230697}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:44,018]\u001b[0m Trial 11 finished with value: 0.7290146707951192 and parameters: {'learning_rate': 0.010199021099969837, 'depth': 5, 'l2_leaf_reg': 2.5815754769703037}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:50,799]\u001b[0m Trial 12 finished with value: 0.7288118295355398 and parameters: {'learning_rate': 0.018007086831084537, 'depth': 5, 'l2_leaf_reg': 2.5672883836456264}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:06:59,705]\u001b[0m Trial 13 finished with value: 0.729602875714807 and parameters: {'learning_rate': 0.017041266654359857, 'depth': 4, 'l2_leaf_reg': 5.96648250185325}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:07:13,399]\u001b[0m Trial 14 finished with value: 0.7305400324360772 and parameters: {'learning_rate': 0.013499657631330538, 'depth': 6, 'l2_leaf_reg': 3.4027213176517415}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:07:20,169]\u001b[0m Trial 15 finished with value: 0.7274088441567823 and parameters: {'learning_rate': 0.013015272485837694, 'depth': 6, 'l2_leaf_reg': 2.0891327485321414}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:07:28,276]\u001b[0m Trial 16 finished with value: 0.7286486418897766 and parameters: {'learning_rate': 0.020571657296439737, 'depth': 7, 'l2_leaf_reg': 5.490965702040379}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:07:30,514]\u001b[0m Trial 17 finished with value: 0.7210528908584353 and parameters: {'learning_rate': 0.09563007865554646, 'depth': 7, 'l2_leaf_reg': 3.2800675597609428}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:07:37,227]\u001b[0m Trial 18 finished with value: 0.7275290206564646 and parameters: {'learning_rate': 0.012981881402549895, 'depth': 6, 'l2_leaf_reg': 1.9283828156471583}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:07:45,423]\u001b[0m Trial 19 finished with value: 0.7302937748110058 and parameters: {'learning_rate': 0.022019086029334365, 'depth': 7, 'l2_leaf_reg': 7.776169792412932}. Best is trial 7 with value: 0.7308668708355023.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.7309\n",
      "  [Optuna] Params: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.7309\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.7315\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_psychiatric.pkl\n",
      "  psychiatric/cat: ROC=0.7309 PR=0.1273 F2=0.3068 P=0.1073 R=0.5738 t=0.539\n",
      "  psychiatric/lgb: ROC=0.6792 PR=0.0942 F2=0.2729 P=0.0890 R=0.5651 t=0.061\n",
      "  psychiatric/xgb: ROC=0.7243 PR=0.1219 F2=0.3007 P=0.1072 R=0.5477 t=0.515\n",
      "  psychiatric/avg: ROC=0.7315 PR=0.1267 F2=0.3070 P=0.1070 R=0.5759 t=0.367\n",
      "\n",
      "  Fairness \u2014 PSYCHIATRIC\n",
      "    Male        : F2=0.2615  P=0.0969  R=0.4545 (n=8,941)\n",
      "    Female      : F2=0.3272  P=0.1111  R=0.6368 (n=10,717)\n",
      "    White       : F2=0.3227  P=0.1171  R=0.5754 (n=13,663)\n",
      "    Black       : F2=0.2687  P=0.0824  R=0.6179 (n=3,289)\n",
      "    Hispanic    : F2=0.2991  P=0.0994  R=0.6016 (n=2,184)\n",
      "    Other       : F2=0.1826  P=0.0748  R=0.2857 (n=522)\n",
      "  Saved SHAP plot: shap_psychiatric.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-15 11:08:20,226]\u001b[0m A new study created in memory with name: no-name-adb4dc06-001a-4958-8ddb-0c9ec5b80571\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "  EXPERT TRAIN & SAVE: MEMORY\n",
      "=================================================================\n",
      "  Scale_pos_weight: 35.15 | Train Size: 35,753\n",
      "  Categorical features: 1\n",
      "  [Optuna] Tuning CatBoost for memory (Max 3 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:08:44,737]\u001b[0m Trial 0 finished with value: 0.8292955560235391 and parameters: {'learning_rate': 0.023688639503640783, 'depth': 8, 'l2_leaf_reg': 5.395030966670228}. Best is trial 0 with value: 0.8292955560235391.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:08:49,036]\u001b[0m Trial 1 finished with value: 0.8310044319087968 and parameters: {'learning_rate': 0.03968793330444373, 'depth': 4, 'l2_leaf_reg': 1.4321698289111515}. Best is trial 1 with value: 0.8310044319087968.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:09:24,917]\u001b[0m Trial 2 finished with value: 0.8281668744986597 and parameters: {'learning_rate': 0.011430983876313222, 'depth': 8, 'l2_leaf_reg': 3.9913058785616786}. Best is trial 1 with value: 0.8310044319087968.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:09:30,164]\u001b[0m Trial 3 finished with value: 0.8312377400814448 and parameters: {'learning_rate': 0.051059032093947576, 'depth': 4, 'l2_leaf_reg': 9.330606024425668}. Best is trial 3 with value: 0.8312377400814448.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:09:36,384]\u001b[0m Trial 4 finished with value: 0.8276358972781502 and parameters: {'learning_rate': 0.06798962421591129, 'depth': 5, 'l2_leaf_reg': 1.5199348301309807}. Best is trial 3 with value: 0.8312377400814448.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:09:51,178]\u001b[0m Trial 5 finished with value: 0.8326536793361364 and parameters: {'learning_rate': 0.015254729458052608, 'depth': 5, 'l2_leaf_reg': 3.347776308515933}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:09:59,807]\u001b[0m Trial 6 finished with value: 0.8316646041214621 and parameters: {'learning_rate': 0.027036160666620016, 'depth': 5, 'l2_leaf_reg': 4.091220574443785}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:10:14,874]\u001b[0m Trial 7 finished with value: 0.8304289699657135 and parameters: {'learning_rate': 0.013787764619353767, 'depth': 5, 'l2_leaf_reg': 2.324672848950434}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:10:24,014]\u001b[0m Trial 8 finished with value: 0.82872577298121 and parameters: {'learning_rate': 0.028580510658069373, 'depth': 7, 'l2_leaf_reg': 1.5837031559118748}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:10:28,597]\u001b[0m Trial 9 finished with value: 0.8243246248967742 and parameters: {'learning_rate': 0.032676417657817626, 'depth': 6, 'l2_leaf_reg': 1.1128853174905728}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:10:40,915]\u001b[0m Trial 10 finished with value: 0.8315183724270436 and parameters: {'learning_rate': 0.016129423372474243, 'depth': 6, 'l2_leaf_reg': 2.489926611953074}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:10:49,444]\u001b[0m Trial 11 finished with value: 0.8313399602950189 and parameters: {'learning_rate': 0.019533168783348334, 'depth': 5, 'l2_leaf_reg': 4.900575376914681}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:11:09,501]\u001b[0m Trial 12 finished with value: 0.8325003490157754 and parameters: {'learning_rate': 0.010365608446758521, 'depth': 5, 'l2_leaf_reg': 7.606246570663321}. Best is trial 5 with value: 0.8326536793361364.\u001b[0m\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "\u001b[32m[I 2026-02-15 11:11:28,009]\u001b[0m Trial 13 finished with value: 0.8334851650548841 and parameters: {'learning_rate': 0.010086482454219638, 'depth': 4, 'l2_leaf_reg': 8.82693076112686}. Best is trial 13 with value: 0.8334851650548841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Optuna] Best AUC: 0.8335\n",
      "  [Optuna] Params: {'learning_rate': 0.010086482454219638, 'depth': 4, 'l2_leaf_reg': 8.82693076112686}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CatBoost (Tuned) AUC: 0.8363\n",
      "  [INFO] LightGBM using CPU fallback.\n",
      "  Ensemble Final AUC: 0.8348\n",
      "  [SAVED] Ensemble saved to /teamspace/studios/this_studio/output_hybrid/saved_models/ensemble_memory.pkl\n",
      "  memory/cat: ROC=0.8363 PR=0.1567 F2=0.3230 P=0.1093 R=0.6316 t=0.597\n",
      "  memory/lgb: ROC=0.8007 PR=0.1354 F2=0.3349 P=0.1542 R=0.4737 t=0.064\n",
      "  memory/xgb: ROC=0.8223 PR=0.1926 F2=0.3291 P=0.1372 R=0.5061 t=0.600\n",
      "  memory/avg: ROC=0.8348 PR=0.1844 F2=0.3453 P=0.1441 R=0.5304 t=0.446\n",
      "\n",
      "  Fairness \u2014 MEMORY\n",
      "    Male        : F2=0.3210  P=0.1320  R=0.5000 (n=3,702)\n",
      "    Female      : F2=0.3605  P=0.1519  R=0.5490 (n=5,100)\n",
      "    White       : F2=0.3333  P=0.1411  R=0.5056 (n=6,854)\n",
      "    Black       : F2=0.4204  P=0.1739  R=0.6512 (n=1,168)\n",
      "    Hispanic    : F2=0.3005  P=0.1209  R=0.4783 (n=628)\n",
      "    Other       : F2=0.3226  P=0.1053  R=0.6667 (n=152)\n",
      "  Saved SHAP plot: shap_memory.png\n",
      "\n",
      "=================================================================\n",
      "  META-ENSEMBLE: ANY-DISEASE ONSET\n",
      "=================================================================\n",
      "\n",
      "  ANY-ONSET Combined:\n",
      "    ROC-AUC:  0.6478\n",
      "    PR-AUC:   0.4899\n",
      "    Best F2:  0.7314 @ threshold 0.600\n",
      "    Samples:  119,986 | Events: 42,228 (35.19%)\n",
      "\n",
      "  Saved feature_importance_experts.csv (1341 rows)\n",
      "\n",
      "  TOP-10 DIABETES:\n",
      "    bmi                            avg=9.7\n",
      "    age                            avg=4.4\n",
      "    condition_count                avg=3.8\n",
      "    bmi_lag1                       avg=3.7\n",
      "    self_rated_health              avg=3.5\n",
      "    age_x_bmi                      avg=2.9\n",
      "    ethnicity                      avg=2.5\n",
      "    weight                         avg=2.2\n",
      "    vigorous_activity_lag2         avg=1.6\n",
      "    self_rated_health_lag2         avg=1.5\n",
      "\n",
      "  TOP-10 CVD:\n",
      "    birth_year                     avg=12.5\n",
      "    condition_count                avg=8.8\n",
      "    self_rated_health              avg=5.3\n",
      "    bmi_x_smoking                  avg=3.5\n",
      "    female                         avg=3.4\n",
      "    age                            avg=3.0\n",
      "    height_lag2                    avg=2.6\n",
      "    out_of_pocket_lag1             avg=2.5\n",
      "    height_lag1                    avg=2.2\n",
      "    weight_lag2                    avg=2.1\n",
      "\n",
      "  TOP-10 STROKE:\n",
      "    age                            avg=3.7\n",
      "    self_rated_health              avg=3.6\n",
      "    condition_count                avg=3.4\n",
      "    age_squared                    avg=3.0\n",
      "    birth_year                     avg=2.2\n",
      "    female                         avg=2.0\n",
      "    memory_recall                  avg=1.6\n",
      "    marital_status_lag2            avg=1.2\n",
      "    bmi_x_smoking                  avg=1.2\n",
      "    mobility                       avg=1.2\n",
      "\n",
      "  TOP-10 LUNG:\n",
      "    self_rated_health              avg=3.4\n",
      "    condition_count                avg=3.2\n",
      "    birth_year                     avg=3.0\n",
      "    ever_smoked                    avg=2.5\n",
      "    mobility                       avg=1.7\n",
      "    age                            avg=1.5\n",
      "    bmi_x_smoking                  avg=1.3\n",
      "    current_smoker_lag2            avg=1.3\n",
      "    bmi_lag1                       avg=1.2\n",
      "    any_mobility                   avg=1.2\n",
      "\n",
      "  TOP-10 CANCER:\n",
      "    female                         avg=4.9\n",
      "    age                            avg=4.6\n",
      "    age_squared                    avg=4.2\n",
      "    height                         avg=3.0\n",
      "    birth_year                     avg=2.9\n",
      "    ethnicity                      avg=2.2\n",
      "    out_of_pocket_lag1             avg=2.0\n",
      "    condition_count                avg=1.4\n",
      "    bmi_lag1                       avg=1.3\n",
      "    education                      avg=1.3\n",
      "\n",
      "  TOP-10 HIBP:\n",
      "    age_x_bmi                      avg=12.3\n",
      "    birth_year                     avg=5.7\n",
      "    cognition                      avg=5.0\n",
      "    self_rated_health              avg=3.6\n",
      "    bmi_x_smoking                  avg=3.6\n",
      "    screening_year                 avg=3.1\n",
      "    bmi_lag1                       avg=3.1\n",
      "    marital_status                 avg=2.8\n",
      "    ethnicity                      avg=2.7\n",
      "    cognition_lag2                 avg=2.6\n",
      "\n",
      "  TOP-10 ARTHRITIS:\n",
      "    large_muscle                   avg=8.7\n",
      "    birth_year                     avg=6.9\n",
      "    female                         avg=6.7\n",
      "    age_x_bmi                      avg=6.6\n",
      "    condition_count                avg=4.4\n",
      "    out_of_pocket_lag1             avg=4.3\n",
      "    age_x_cesd                     avg=3.6\n",
      "    out_of_pocket                  avg=3.6\n",
      "    bmi                            avg=3.0\n",
      "    screening_year                 avg=3.0\n",
      "\n",
      "  TOP-10 PSYCHIATRIC:\n",
      "    self_rated_health              avg=2.7\n",
      "    age_x_cesd                     avg=2.1\n",
      "    cognition                      avg=2.0\n",
      "    cesd_lag1                      avg=1.7\n",
      "    cesd_lag2                      avg=1.6\n",
      "    out_of_pocket                  avg=1.5\n",
      "    condition_count                avg=1.4\n",
      "    out_of_pocket_lag2             avg=1.4\n",
      "    female                         avg=1.4\n",
      "    cesd                           avg=1.3\n",
      "\n",
      "  TOP-10 MEMORY:\n",
      "    age                            avg=3.9\n",
      "    out_of_pocket_lag2             avg=3.2\n",
      "    out_of_pocket_lag1             avg=3.0\n",
      "    delayed_recall                 avg=2.7\n",
      "    memory_recall                  avg=2.7\n",
      "    birth_year                     avg=2.6\n",
      "    cognition                      avg=2.4\n",
      "    age_x_cesd                     avg=2.2\n",
      "    bmi_delta_lag2                 avg=2.2\n",
      "    weight                         avg=2.1\n",
      "\n",
      "  Saved results.json\n",
      "\n",
      "=================================================================\n",
      "  FINAL SUMMARY\n",
      "=================================================================\n",
      "Disease         ROC-AUC   PR-AUC       F2   Recall     Prec\n",
      "--------------------------------------------------------------\n",
      "diabetes         0.7034   0.1405   0.3593   0.6707   0.1257\n",
      "cvd              0.6902   0.1843   0.4052   0.7824   0.1384\n",
      "stroke           0.6922   0.0677   0.2041   0.5863   0.0566\n",
      "lung             0.7365   0.1023   0.2644   0.4058   0.1104\n",
      "cancer           0.5946   0.0768   0.2309   0.6989   0.0628\n",
      "hibp             0.6180   0.2713   0.5639   0.9422   0.2164\n",
      "arthritis        0.6461   0.3058   0.5629   0.9832   0.2077\n",
      "psychiatric      0.7315   0.1267   0.3070   0.5759   0.1070\n",
      "memory           0.8348   0.1844   0.3453   0.5304   0.1441\n",
      "ANY-ONSET        0.6478   0.4899   0.7314\n"
     ]
    }
   ],
   "source": [
    "\n",
    "banner(\"HYBRID DISEASE-EXPERT ENSEMBLE\")\n",
    "print(f\"  Data:    {DATA_PATH}\")\n",
    "print(f\"  Output:  {OUTPUT_DIR}\")\n",
    "print(f\"  Horizon: {PREDICTION_HORIZON} screenings (~{PREDICTION_HORIZON*2} years)\")\n",
    "print(f\"  Diseases: {list(DISEASE_MAP.keys())}\")\n",
    "\n",
    "# Load raw\n",
    "print(\"\\n  Loading parquet data...\")\n",
    "df_raw = pd.read_parquet(str(DATA_PATH))\n",
    "print(f\"  Shape: {df_raw.shape}\")\n",
    "\n",
    "# Build master feature+target dataset\n",
    "master = build_master_features(df_raw)\n",
    "\n",
    "# Train one expert per disease\n",
    "all_models = {}\n",
    "all_results = {}\n",
    "all_feature_cols = {}\n",
    "\n",
    "for disease in DISEASE_MAP:\n",
    "    try:\n",
    "        feature_cols, X_tr, y_tr, X_te, y_te, demo = get_disease_dataset(master, disease)\n",
    "        all_feature_cols[disease] = feature_cols\n",
    "\n",
    "        models, results, avg_pred = train_disease_expert(\n",
    "            disease, feature_cols, X_tr, y_tr, X_te, y_te\n",
    "        )\n",
    "        all_models[disease] = models\n",
    "        all_results[disease] = results\n",
    "\n",
    "        # Best threshold from ensemble average\n",
    "        bt = results[\"avg\"][\"threshold\"]\n",
    "        fairness_audit(disease, y_te, avg_pred, bt, demo)\n",
    "        explain_expert(models, X_te, feature_cols, disease)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n  ERROR for {disease}: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Meta-ensemble: any-onset\n",
    "if all_models:\n",
    "    any_onset_results = build_any_onset_from_experts(\n",
    "        master, all_models, all_feature_cols\n",
    "    )\n",
    "    all_results[\"_any_onset_combined\"] = any_onset_results\n",
    "\n",
    "# Export\n",
    "if all_models:\n",
    "    export_importance(all_models, all_feature_cols)\n",
    "\n",
    "# Save results\n",
    "with open(OUTPUT_DIR / \"results.json\", \"w\") as f:\n",
    "    json.dump(all_results, f, indent=2, default=str)\n",
    "print(\"\\n  Saved results.json\")\n",
    "\n",
    "banner(\"FINAL SUMMARY\")\n",
    "print(f\"{'Disease':<14} {'ROC-AUC':>8} {'PR-AUC':>8} {'F2':>8} {'Recall':>8} {'Prec':>8}\")\n",
    "print(\"-\" * 62)\n",
    "for disease, res in all_results.items():\n",
    "    if disease.startswith(\"_\"):\n",
    "        # Meta-ensemble\n",
    "        r = res\n",
    "        print(f\"{'ANY-ONSET':<14} {r.get('roc_auc',0):>8.4f} {r.get('pr_auc',0):>8.4f} \"\n",
    "                f\"{r.get('f2',0):>8.4f}\")\n",
    "    else:\n",
    "        r = res.get(\"avg\", {})\n",
    "        print(f\"{disease:<14} {r.get('roc_auc',0):>8.4f} {r.get('pr_auc',0):>8.4f} \"\n",
    "                f\"{r.get('f2',0):>8.4f} {r.get('recall',0):>8.4f} {r.get('precision',0):>8.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}